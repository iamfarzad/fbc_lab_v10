{
  "tools/calculate-roi": {
    "status": "identical",
    "differences": [],
    "stats": {
      "source": {
        "lines": 192,
        "exports": 0,
        "functions": 2,
        "classes": 0
      },
      "target": {
        "lines": 187,
        "exports": 0,
        "functions": 2,
        "classes": 0
      }
    },
    "content1": "/**\n * Calculate ROI Tool Executor\n * \n * Calculates ROI from investment/savings parameters or extracts from existing artifact.\n */\n\nimport type { ROICalculationResult } from './tool-types.js'\nimport { isValidROIData, type ROIData } from '../pdf-roi-charts.js'\nimport { ContextStorage } from '../../context/context-storage.js'\n\nconst contextStorage = new ContextStorage()\n\ninterface ROIParameters {\n  currentCost?: number\n  timeSavings?: number\n  employeeCostPerHour?: number\n  implementationCost?: number\n  timeline?: number\n  // Or direct ROI data structure\n  initialInvestment?: number\n  annualCost?: number\n  staffReductionSavings?: number\n  efficiencySavings?: number\n  retentionSavings?: number\n}\n\n/**\n * Calculate ROI from parameters or extract from artifact\n * \n * @param sessionId - Session ID to check for ROI artifact\n * @param params - ROI calculation parameters\n * @returns Calculated ROI metrics\n */\nexport async function calculateROI(\n  sessionId: string,\n  params: ROIParameters = {}\n): Promise<ROICalculationResult> {\n  try {\n    let roiData: ROIData | null = null\n\n    // First, try to extract from artifact if no parameters provided\n    if (Object.keys(params).length === 0) {\n      const context = await contextStorage.get(sessionId)\n      if (context) {\n        // Check if artifactInsights exists in context (might be in multimodal_context or as separate field)\n        const contextRecord = context as unknown as Record<string, unknown>\n        const multimodalContext = contextRecord.multimodal_context as Record<string, unknown> | undefined\n        const artifactInsights = contextRecord.artifactInsights || multimodalContext?.artifactInsights\n        \n        if (artifactInsights) {\n          const artifacts = Array.isArray(artifactInsights) \n            ? artifactInsights \n            : typeof artifactInsights === 'string'\n            ? JSON.parse(artifactInsights) as unknown[]\n            : []\n          \n          interface Artifact {\n            type?: string\n            payload?: unknown\n          }\n          const roiArtifact = artifacts.find(\n            (a: unknown): a is Artifact => {\n              const artifact = a as Artifact\n              return artifact.type === 'Cost-Benefit Analysis' && artifact.payload !== undefined && isValidROIData(artifact.payload)\n            }\n          )\n          \n          if (roiArtifact && isValidROIData(roiArtifact.payload)) {\n            roiData = roiArtifact.payload\n          }\n        }\n      }\n    }\n\n    // If no artifact found, calculate from parameters\n    if (!roiData) {\n      // Use direct ROI structure if provided\n      if (\n        typeof params.initialInvestment === 'number' &&\n        typeof params.annualCost === 'number' &&\n        typeof params.staffReductionSavings === 'number' &&\n        typeof params.efficiencySavings === 'number' &&\n        typeof params.retentionSavings === 'number'\n      ) {\n        const totalSavings = \n          params.staffReductionSavings + \n          params.efficiencySavings + \n          params.retentionSavings\n        \n        const totalInvestment = params.initialInvestment + params.annualCost\n        const firstYearROI = totalSavings - totalInvestment\n        \n        // Calculate payback period (months)\n        const monthlySavings = totalSavings / 12\n        const paybackMonths = totalInvestment / monthlySavings\n        \n        roiData = {\n          investment: {\n            initial: params.initialInvestment,\n            annual: params.annualCost\n          },\n          savings: {\n            staffReduction: params.staffReductionSavings,\n            efficiency: params.efficiencySavings,\n            retention: params.retentionSavings\n          },\n          roi: {\n            firstYear: firstYearROI,\n            paybackPeriod: `${paybackMonths.toFixed(1)} months`\n          }\n        }\n      } else if (\n        typeof params.implementationCost === 'number' &&\n        typeof params.timeSavings === 'number' &&\n        typeof params.employeeCostPerHour === 'number'\n      ) {\n        // Calculate from simplified parameters\n        const annualSavings = params.timeSavings * params.employeeCostPerHour\n        const initialInvestment = params.implementationCost\n        const annualCost = params.currentCost || 0\n        \n        const totalInvestment = initialInvestment + annualCost\n        const firstYearROI = annualSavings - totalInvestment\n        \n        // Calculate payback period (months)\n        const monthlySavings = annualSavings / 12\n        const paybackMonths = totalInvestment / monthlySavings\n        \n        roiData = {\n          investment: {\n            initial: initialInvestment,\n            annual: annualCost\n          },\n          savings: {\n            staffReduction: 0,\n            efficiency: annualSavings,\n            retention: 0\n          },\n          roi: {\n            firstYear: firstYearROI,\n            paybackPeriod: `${paybackMonths.toFixed(1)} months`\n          }\n        }\n      } else {\n        throw new Error(\n          'ROI calculation requires either: ' +\n          '(1) ROI artifact in session, or ' +\n          '(2) initialInvestment, annualCost, staffReductionSavings, efficiencySavings, retentionSavings, or ' +\n          '(3) implementationCost, timeSavings, employeeCostPerHour'\n        )\n      }\n    }\n\n    // Calculate final metrics\n    const typedRoiData = roiData as {\n      investment: { initial: number; annual: number }\n      savings: { staffReduction: number; efficiency: number; retention: number }\n      roi: { firstYear: number; paybackPeriod: string }\n    }\n    const investmentTotal = typedRoiData.investment.initial + typedRoiData.investment.annual\n    const savingsTotal = \n      typedRoiData.savings.staffReduction + \n      typedRoiData.savings.efficiency + \n      typedRoiData.savings.retention\n    \n    const firstYearROI = typedRoiData.roi.firstYear as number\n    const roiPercentage = investmentTotal > 0 \n      ? ((firstYearROI - investmentTotal) / investmentTotal) * 100 \n      : 0\n    \n    // Estimate three-year ROI (assume same savings each year)\n    const threeYearROI = (savingsTotal * 3) - (investmentTotal + typedRoiData.investment.annual * 2)\n\n    return {\n      paybackPeriod: typedRoiData.roi.paybackPeriod,\n      firstYearROI,\n      threeYearROI,\n      roiPercentage: Number(roiPercentage.toFixed(1)),\n      totalInvestment: investmentTotal,\n      totalSavings: savingsTotal\n    }\n  } catch (error) {\n    console.error('[calculateROI] Error:', error)\n    throw new Error(\n      error instanceof Error \n        ? `Failed to calculate ROI: ${error.message}`\n        : 'Failed to calculate ROI'\n    )\n  }\n}\n\n",
    "content2": "/**\n * Calculate ROI Tool Executor\n * \n * Calculates ROI from investment/savings parameters or extracts from existing artifact.\n */\n\nimport type { ROICalculationResult } from './tool-types'\nimport { isValidROIData, type ROIData } from '../pdf-roi-charts'\nimport { ContextStorage } from '../context/context-storage'\n\nconst contextStorage = new ContextStorage()\n\ninterface ROIParameters {\n  currentCost?: number\n  timeSavings?: number\n  employeeCostPerHour?: number\n  implementationCost?: number\n  timeline?: number\n  // Or direct ROI data structure\n  initialInvestment?: number\n  annualCost?: number\n  staffReductionSavings?: number\n  efficiencySavings?: number\n  retentionSavings?: number\n}\n\n/**\n * Calculate ROI from parameters or extract from artifact\n * \n * @param sessionId - Session ID to check for ROI artifact\n * @param params - ROI calculation parameters\n * @returns Calculated ROI metrics\n */\nexport async function calculateROI(\n  sessionId: string,\n  params: ROIParameters = {}\n): Promise<ROICalculationResult> {\n  try {\n    let roiData: ROIData | null = null\n\n    // First, try to extract from artifact if no parameters provided\n    if (Object.keys(params).length === 0) {\n      const context = await contextStorage.get(sessionId)\n      if (context) {\n        // Check if artifactInsights exists in context (might be in multimodal_context or as separate field)\n        const contextRecord = context as unknown as Record<string, unknown>\n        const multimodalContext = contextRecord.multimodal_context as Record<string, unknown> | undefined\n        const artifactInsights = contextRecord.artifactInsights || multimodalContext?.artifactInsights\n        \n        if (artifactInsights) {\n          const artifacts = Array.isArray(artifactInsights) \n            ? artifactInsights \n            : typeof artifactInsights === 'string'\n            ? JSON.parse(artifactInsights) as unknown[]\n            : []\n          \n          interface Artifact {\n            type?: string\n            payload?: unknown\n          }\n          const roiArtifact = artifacts.find(\n            (a: unknown): a is Artifact => {\n              const artifact = a as Artifact\n              return artifact.type === 'Cost-Benefit Analysis' && artifact.payload !== undefined && isValidROIData(artifact.payload)\n            }\n          )\n          \n          if (roiArtifact && isValidROIData(roiArtifact.payload)) {\n            roiData = roiArtifact.payload\n          }\n        }\n      }\n    }\n\n    // If no artifact found, calculate from parameters\n    if (!roiData) {\n      // Use direct ROI structure if provided\n      if (\n        typeof params.initialInvestment === 'number' &&\n        typeof params.annualCost === 'number' &&\n        typeof params.staffReductionSavings === 'number' &&\n        typeof params.efficiencySavings === 'number' &&\n        typeof params.retentionSavings === 'number'\n      ) {\n        const totalSavings = \n          params.staffReductionSavings + \n          params.efficiencySavings + \n          params.retentionSavings\n        \n        const totalInvestment = params.initialInvestment + params.annualCost\n        const firstYearROI = totalSavings - totalInvestment\n        \n        // Calculate payback period (months)\n        const monthlySavings = totalSavings / 12\n        const paybackMonths = totalInvestment / monthlySavings\n        \n        roiData = {\n          investment: {\n            initial: params.initialInvestment,\n            annual: params.annualCost\n          },\n          savings: {\n            staffReduction: params.staffReductionSavings,\n            efficiency: params.efficiencySavings,\n            retention: params.retentionSavings\n          },\n          roi: {\n            firstYear: firstYearROI,\n            paybackPeriod: `${paybackMonths.toFixed(1)} months`\n          }\n        }\n      } else if (\n        typeof params.implementationCost === 'number' &&\n        typeof params.timeSavings === 'number' &&\n        typeof params.employeeCostPerHour === 'number'\n      ) {\n        // Calculate from simplified parameters\n        const annualSavings = params.timeSavings * params.employeeCostPerHour\n        const initialInvestment = params.implementationCost\n        const annualCost = params.currentCost || 0\n        \n        const totalInvestment = initialInvestment + annualCost\n        const firstYearROI = annualSavings - totalInvestment\n        \n        // Calculate payback period (months)\n        const monthlySavings = annualSavings / 12\n        const paybackMonths = totalInvestment / monthlySavings\n        \n        roiData = {\n          investment: {\n            initial: initialInvestment,\n            annual: annualCost\n          },\n          savings: {\n            staffReduction: 0,\n            efficiency: annualSavings,\n            retention: 0\n          },\n          roi: {\n            firstYear: firstYearROI,\n            paybackPeriod: `${paybackMonths.toFixed(1)} months`\n          }\n        }\n      } else {\n        throw new Error(\n          'ROI calculation requires either: ' +\n          '(1) ROI artifact in session, or ' +\n          '(2) initialInvestment, annualCost, staffReductionSavings, efficiencySavings, retentionSavings, or ' +\n          '(3) implementationCost, timeSavings, employeeCostPerHour'\n        )\n      }\n    }\n\n    // Calculate final metrics\n    const investmentTotal = roiData.investment.initial + roiData.investment.annual\n    const savingsTotal = \n      roiData.savings.staffReduction + \n      roiData.savings.efficiency + \n      roiData.savings.retention\n    \n    const firstYearROI = roiData.roi.firstYear\n    const roiPercentage = investmentTotal > 0 \n      ? ((firstYearROI - investmentTotal) / investmentTotal) * 100 \n      : 0\n    \n    // Estimate three-year ROI (assume same savings each year)\n    const threeYearROI = (savingsTotal * 3) - (investmentTotal + roiData.investment.annual * 2)\n\n    return {\n      paybackPeriod: roiData.roi.paybackPeriod,\n      firstYearROI,\n      threeYearROI,\n      roiPercentage: Number(roiPercentage.toFixed(1)),\n      totalInvestment: investmentTotal,\n      totalSavings: savingsTotal\n    }\n  } catch (error) {\n    console.error('[calculateROI] Error:', error)\n    throw new Error(\n      error instanceof Error \n        ? `Failed to calculate ROI: ${error.message}`\n        : 'Failed to calculate ROI'\n    )\n  }\n}\n\n"
  },
  "tools/draft-follow-up-email": {
    "status": "identical",
    "differences": [],
    "stats": {
      "source": {
        "lines": 164,
        "exports": 0,
        "functions": 2,
        "classes": 0
      },
      "target": {
        "lines": 164,
        "exports": 0,
        "functions": 2,
        "classes": 0
      }
    },
    "content1": "/**\n * Draft Follow-Up Email Tool Executor\n * \n * Drafts personalized follow-up emails based on conversation\n * using the retargetingAgent pattern adapted for mid-session use.\n */\n\nimport { google, generateText } from '../../utils/ai-client.js'\nimport { GEMINI_MODELS } from '../../config/constants.js'\nimport { multimodalContextManager } from '../../context/multimodal-context.js'\nimport { ContextStorage } from '../../context/context-storage.js'\nimport type { EmailDraftResult } from './tool-types.js'\nimport { extractConversationInsights, buildConversationPairs } from '../pdf-generator-puppeteer.js'\n\nconst contextStorage = new ContextStorage()\n\ninterface EmailDraftOptions {\n  recipient: 'client' | 'team' | 'farzad'\n  tone: 'professional' | 'casual' | 'technical'\n  includeSummary?: boolean\n}\n\n/**\n * Draft follow-up email based on conversation\n * \n * @param sessionId - Session ID to get conversation data from\n * @param options - Email draft options\n * @returns Drafted email with subject, body, and CTA\n */\nexport async function draftFollowUpEmail(\n  sessionId: string,\n  options: EmailDraftOptions\n): Promise<EmailDraftResult> {\n  try {\n    // Get conversation context\n    const context = await multimodalContextManager.getConversationContext(sessionId, false, false)\n    \n    // Get lead context\n    const leadContext = await contextStorage.get(sessionId)\n    const leadName = leadContext?.name || 'there'\n    const companyContext = leadContext?.company_context\n    const companyName = (companyContext && typeof companyContext === 'object' && 'name' in companyContext && typeof companyContext.name === 'string')\n      ? companyContext.name\n      : leadContext?.name || 'your company'\n    const leadEmail = leadContext?.email || ''\n\n    // Build conversation summary from insights\n    let conversationSummary = ''\n    if (context.conversationHistory.length > 0) {\n      const conversationHistory = context.conversationHistory.map((entry: { metadata?: { speaker?: string }; content?: string; timestamp?: string }) => {\n        const role = entry.metadata?.speaker === 'model' || entry.metadata?.speaker === 'assistant' \n          ? 'assistant' \n          : 'user'\n        \n        return {\n          role: role as 'user' | 'assistant',\n          content: entry.content || '',\n          timestamp: entry.timestamp\n        }\n      })\n\n      const pairs = buildConversationPairs(conversationHistory)\n      const insights = extractConversationInsights(pairs)\n\n      conversationSummary = `Conversation highlights:\n- Recommendations discussed: ${insights.recommendations.length > 0 ? insights.recommendations.slice(0, 2).join('; ') : 'None yet'}\n- Next steps identified: ${insights.nextSteps.length > 0 ? insights.nextSteps.slice(0, 2).join('; ') : 'None yet'}\n- Key decisions: ${insights.keyDecisions.length > 0 ? insights.keyDecisions.slice(0, 2).join('; ') : 'None yet'}\n- Total messages exchanged: ${context.conversationHistory.length}`\n    } else {\n      conversationSummary = 'Early conversation - limited context available.'\n    }\n\n    // Build system prompt based on recipient and tone\n    const toneStyle = {\n      professional: 'Professional and polished, business-appropriate language.',\n      casual: 'Conversational and friendly, approachable tone.',\n      technical: 'Technical and precise, detail-oriented language.'\n    }\n\n    const recipientContext = {\n      client: `Email to: ${leadName} (${leadEmail}) at ${companyName}`,\n      team: `Internal email to Farzad's team summarizing the conversation with ${leadName}`,\n      farzad: `Email to Farzad summarizing the conversation with ${leadName} from ${companyName}`\n    }\n\n    const systemPrompt = `You are F.B/c AI - draft follow-up emails.\n\nLEAD INFORMATION:\n${JSON.stringify({\n  name: leadName,\n  email: leadEmail,\n  company: companyName\n}, null, 2)}\n\nCONVERSATION SUMMARY:\n${options.includeSummary ? conversationSummary : 'Summary requested to be omitted.'}\n\n${recipientContext[options.recipient]}\n\nTONE: ${toneStyle[options.tone]}\n\nEMAIL GUIDELINES:\n- Subject line should be clear and actionable\n- Body should reference specific conversation points if summary is included\n- Include a clear call-to-action\n- Keep it concise (2-3 paragraphs max)\n- Match the specified tone\n\nOUTPUT FORMAT (JSON):\n{\n  \"subject\": \"Email subject line\",\n  \"body\": \"Email body text with proper formatting\",\n  \"cta\": \"Primary call-to-action text\"\n}\n\nTONE: ${options.tone === 'professional' ? 'Professional but warm' : options.tone === 'casual' ? 'Casual and friendly' : 'Technical and precise'}`\n\n    const result = await generateText({\n      model: google(GEMINI_MODELS.DEFAULT_CHAT),\n      messages: [\n        { role: 'system', content: systemPrompt },\n        { role: 'user', content: `Generate a ${options.tone} follow-up email for ${options.recipient}.` }\n      ],\n      temperature: 0.7\n    })\n\n    // Parse JSON from response\n    let email: EmailDraftResult\n    try {\n      const jsonMatch = result.text.match(/\\{[\\s\\S]*\\}/)\n      if (jsonMatch) {\n        email = JSON.parse(jsonMatch[0]) as EmailDraftResult\n      } else {\n        throw new Error('No JSON found in email response')\n      }\n    } catch (error) {\n      console.error('Failed to parse email draft:', error)\n      // Fallback email\n      email = {\n        subject: `Following up on our AI conversation${options.recipient === 'farzad' ? ` - ${leadName}` : ''}`,\n        body: `Hi ${options.recipient === 'client' ? leadName : options.recipient === 'team' ? 'Team' : 'Farzad'},\n\n${options.includeSummary ? conversationSummary : 'I wanted to follow up on our recent conversation about AI strategy.'}\n\n${options.recipient === 'client' ? 'Let me know if you\\'d like to continue the discussion.' : 'Thought you\\'d want an update on this conversation.'}\n\nBest,\n${options.recipient === 'client' ? 'F.B/c Team' : 'AI Assistant'}`,\n        cta: options.recipient === 'client' ? 'Reply to this email' : 'Review conversation details'\n      }\n    }\n\n    return email\n  } catch (error) {\n    console.error('[draftFollowUpEmail] Error:', error)\n    throw new Error(\n      error instanceof Error \n        ? `Failed to draft follow-up email: ${error.message}`\n        : 'Failed to draft follow-up email'\n    )\n  }\n}\n",
    "content2": "/**\n * Draft Follow-Up Email Tool Executor\n * \n * Drafts personalized follow-up emails based on conversation\n * using the retargetingAgent pattern adapted for mid-session use.\n */\n\nimport { google, generateText } from '@/lib/ai-client'\nimport { GEMINI_MODELS } from '@/config/constants'\nimport { multimodalContextManager } from '../context/multimodal-context'\nimport { ContextStorage } from '../context/context-storage'\nimport type { EmailDraftResult } from './tool-types'\nimport { extractConversationInsights, buildConversationPairs } from '../pdf-generator-puppeteer'\n\nconst contextStorage = new ContextStorage()\n\ninterface EmailDraftOptions {\n  recipient: 'client' | 'team' | 'farzad'\n  tone: 'professional' | 'casual' | 'technical'\n  includeSummary?: boolean\n}\n\n/**\n * Draft follow-up email based on conversation\n * \n * @param sessionId - Session ID to get conversation data from\n * @param options - Email draft options\n * @returns Drafted email with subject, body, and CTA\n */\nexport async function draftFollowUpEmail(\n  sessionId: string,\n  options: EmailDraftOptions\n): Promise<EmailDraftResult> {\n  try {\n    // Get conversation context\n    const context = await multimodalContextManager.getConversationContext(sessionId, false, false)\n    \n    // Get lead context\n    const leadContext = await contextStorage.get(sessionId)\n    const leadName = leadContext?.name || 'there'\n    const companyContext = leadContext?.company_context\n    const companyName = (companyContext && typeof companyContext === 'object' && 'name' in companyContext && typeof companyContext.name === 'string')\n      ? companyContext.name\n      : leadContext?.name || 'your company'\n    const leadEmail = leadContext?.email || ''\n\n    // Build conversation summary from insights\n    let conversationSummary = ''\n    if (context.conversationHistory.length > 0) {\n      const conversationHistory = context.conversationHistory.map(entry => {\n        const role = entry.metadata?.speaker === 'model' || entry.metadata?.speaker === 'assistant' \n          ? 'assistant' \n          : 'user'\n        \n        return {\n          role: role as 'user' | 'assistant',\n          content: entry.content || '',\n          timestamp: entry.timestamp\n        }\n      })\n\n      const pairs = buildConversationPairs(conversationHistory)\n      const insights = extractConversationInsights(pairs)\n\n      conversationSummary = `Conversation highlights:\n- Recommendations discussed: ${insights.recommendations.length > 0 ? insights.recommendations.slice(0, 2).join('; ') : 'None yet'}\n- Next steps identified: ${insights.nextSteps.length > 0 ? insights.nextSteps.slice(0, 2).join('; ') : 'None yet'}\n- Key decisions: ${insights.keyDecisions.length > 0 ? insights.keyDecisions.slice(0, 2).join('; ') : 'None yet'}\n- Total messages exchanged: ${context.conversationHistory.length}`\n    } else {\n      conversationSummary = 'Early conversation - limited context available.'\n    }\n\n    // Build system prompt based on recipient and tone\n    const toneStyle = {\n      professional: 'Professional and polished, business-appropriate language.',\n      casual: 'Conversational and friendly, approachable tone.',\n      technical: 'Technical and precise, detail-oriented language.'\n    }\n\n    const recipientContext = {\n      client: `Email to: ${leadName} (${leadEmail}) at ${companyName}`,\n      team: `Internal email to Farzad's team summarizing the conversation with ${leadName}`,\n      farzad: `Email to Farzad summarizing the conversation with ${leadName} from ${companyName}`\n    }\n\n    const systemPrompt = `You are F.B/c AI - draft follow-up emails.\n\nLEAD INFORMATION:\n${JSON.stringify({\n  name: leadName,\n  email: leadEmail,\n  company: companyName\n}, null, 2)}\n\nCONVERSATION SUMMARY:\n${options.includeSummary ? conversationSummary : 'Summary requested to be omitted.'}\n\n${recipientContext[options.recipient]}\n\nTONE: ${toneStyle[options.tone]}\n\nEMAIL GUIDELINES:\n- Subject line should be clear and actionable\n- Body should reference specific conversation points if summary is included\n- Include a clear call-to-action\n- Keep it concise (2-3 paragraphs max)\n- Match the specified tone\n\nOUTPUT FORMAT (JSON):\n{\n  \"subject\": \"Email subject line\",\n  \"body\": \"Email body text with proper formatting\",\n  \"cta\": \"Primary call-to-action text\"\n}\n\nTONE: ${options.tone === 'professional' ? 'Professional but warm' : options.tone === 'casual' ? 'Casual and friendly' : 'Technical and precise'}`\n\n    const result = await generateText({\n      model: google(GEMINI_MODELS.DEFAULT_CHAT),\n      messages: [\n        { role: 'system', content: systemPrompt },\n        { role: 'user', content: `Generate a ${options.tone} follow-up email for ${options.recipient}.` }\n      ],\n      temperature: 0.7\n    })\n\n    // Parse JSON from response\n    let email: EmailDraftResult\n    try {\n      const jsonMatch = result.text.match(/\\{[\\s\\S]*\\}/)\n      if (jsonMatch) {\n        email = JSON.parse(jsonMatch[0]) as EmailDraftResult\n      } else {\n        throw new Error('No JSON found in email response')\n      }\n    } catch (error) {\n      console.error('Failed to parse email draft:', error)\n      // Fallback email\n      email = {\n        subject: `Following up on our AI conversation${options.recipient === 'farzad' ? ` - ${leadName}` : ''}`,\n        body: `Hi ${options.recipient === 'client' ? leadName : options.recipient === 'team' ? 'Team' : 'Farzad'},\n\n${options.includeSummary ? conversationSummary : 'I wanted to follow up on our recent conversation about AI strategy.'}\n\n${options.recipient === 'client' ? 'Let me know if you\\'d like to continue the discussion.' : 'Thought you\\'d want an update on this conversation.'}\n\nBest,\n${options.recipient === 'client' ? 'F.B/c Team' : 'AI Assistant'}`,\n        cta: options.recipient === 'client' ? 'Reply to this email' : 'Review conversation details'\n      }\n    }\n\n    return email\n  } catch (error) {\n    console.error('[draftFollowUpEmail] Error:', error)\n    throw new Error(\n      error instanceof Error \n        ? `Failed to draft follow-up email: ${error.message}`\n        : 'Failed to draft follow-up email'\n    )\n  }\n}\n"
  },
  "tools/extract-action-items": {
    "status": "identical",
    "differences": [],
    "stats": {
      "source": {
        "lines": 68,
        "exports": 0,
        "functions": 1,
        "classes": 0
      },
      "target": {
        "lines": 68,
        "exports": 0,
        "functions": 1,
        "classes": 0
      }
    },
    "content1": "/**\n * Extract Action Items Tool Executor\n * \n * Extracts recommendations, next steps, key decisions, and important points\n * from the current conversation history.\n */\n\nimport { extractConversationInsights, buildConversationPairs } from '../pdf-generator-puppeteer.js'\nimport { multimodalContextManager } from '../../context/multimodal-context.js'\nimport type { ActionItemsResult } from './tool-types.js'\n\n/**\n * Extract action items from conversation history\n * \n * @param sessionId - Session ID to get conversation history from\n * @returns Structured insights with recommendations, next steps, decisions, and important points\n */\nexport async function extractActionItems(sessionId: string): Promise<ActionItemsResult> {\n  try {\n    // Get conversation context from MultimodalContextManager\n    const context = await multimodalContextManager.getConversationContext(sessionId, false, false)\n    \n    if (!context.conversationHistory || context.conversationHistory.length === 0) {\n      return {\n        recommendations: [],\n        nextSteps: [],\n        keyDecisions: [],\n        importantPoints: []\n      }\n    }\n\n    // Convert ConversationEntry[] to format expected by buildConversationPairs\n    const conversationHistory = context.conversationHistory.map(entry => {\n      // Determine role from metadata.speaker or default to 'user' for text entries\n      const role = entry.metadata?.speaker === 'model' || entry.metadata?.speaker === 'assistant' \n        ? 'assistant' \n        : 'user'\n      \n      return {\n        role: role as 'user' | 'assistant',\n        content: entry.content || '',\n        timestamp: entry.timestamp\n      }\n    })\n\n    // Build conversation pairs\n    const pairs = buildConversationPairs(conversationHistory)\n\n    // Extract insights\n    const insights = extractConversationInsights(pairs)\n\n    return {\n      recommendations: insights.recommendations,\n      nextSteps: insights.nextSteps,\n      keyDecisions: insights.keyDecisions,\n      importantPoints: insights.importantPoints\n    }\n  } catch (error) {\n    console.error('[extractActionItems] Error:', error)\n    throw new Error(\n      error instanceof Error \n        ? `Failed to extract action items: ${error.message}`\n        : 'Failed to extract action items from conversation'\n    )\n  }\n}\n\n",
    "content2": "/**\n * Extract Action Items Tool Executor\n * \n * Extracts recommendations, next steps, key decisions, and important points\n * from the current conversation history.\n */\n\nimport { extractConversationInsights, buildConversationPairs } from '../pdf-generator-puppeteer'\nimport { multimodalContextManager } from '../context/multimodal-context'\nimport type { ActionItemsResult } from './tool-types'\n\n/**\n * Extract action items from conversation history\n * \n * @param sessionId - Session ID to get conversation history from\n * @returns Structured insights with recommendations, next steps, decisions, and important points\n */\nexport async function extractActionItems(sessionId: string): Promise<ActionItemsResult> {\n  try {\n    // Get conversation context from MultimodalContextManager\n    const context = await multimodalContextManager.getConversationContext(sessionId, false, false)\n    \n    if (!context.conversationHistory || context.conversationHistory.length === 0) {\n      return {\n        recommendations: [],\n        nextSteps: [],\n        keyDecisions: [],\n        importantPoints: []\n      }\n    }\n\n    // Convert ConversationEntry[] to format expected by buildConversationPairs\n    const conversationHistory = context.conversationHistory.map(entry => {\n      // Determine role from metadata.speaker or default to 'user' for text entries\n      const role = entry.metadata?.speaker === 'model' || entry.metadata?.speaker === 'assistant' \n        ? 'assistant' \n        : 'user'\n      \n      return {\n        role: role as 'user' | 'assistant',\n        content: entry.content || '',\n        timestamp: entry.timestamp\n      }\n    })\n\n    // Build conversation pairs\n    const pairs = buildConversationPairs(conversationHistory)\n\n    // Extract insights\n    const insights = extractConversationInsights(pairs)\n\n    return {\n      recommendations: insights.recommendations,\n      nextSteps: insights.nextSteps,\n      keyDecisions: insights.keyDecisions,\n      importantPoints: insights.importantPoints\n    }\n  } catch (error) {\n    console.error('[extractActionItems] Error:', error)\n    throw new Error(\n      error instanceof Error \n        ? `Failed to extract action items: ${error.message}`\n        : 'Failed to extract action items from conversation'\n    )\n  }\n}\n\n"
  },
  "tools/generate-proposal": {
    "status": "identical",
    "differences": [],
    "stats": {
      "source": {
        "lines": 112,
        "exports": 0,
        "functions": 1,
        "classes": 0
      },
      "target": {
        "lines": 112,
        "exports": 0,
        "functions": 1,
        "classes": 0
      }
    },
    "content1": "/**\n * Generate Proposal Tool Executor\n * \n * Generates a proposal based on conversation (wraps /api/generate-proposal logic).\n */\n\nimport { generateText, google } from ['\"]../../utils/ai-client.js'\nimport { CONTACT_CONFIG, GEMINI_MODELS } from ['\"]../../config/constants.js'\nimport { ContextStorage } from '../../context/context-storage.js'\nimport { usageLimiter } from ['\"]../../utils/usage-limits.js'\n\nconst contextStorage = new ContextStorage()\n\n/**\n * Generate proposal text from conversation\n * \n * @param sessionId - Session ID to get conversation data from\n * @returns Markdown-formatted proposal text\n */\nexport async function generateProposal(sessionId: string): Promise<string> {\n  try {\n    // Get conversation context\n    const context = await contextStorage.get(sessionId)\n    const usage = await usageLimiter.getUsage(sessionId)\n    \n    if (!context || !usage) {\n      throw new Error('Session not found or no usage data available')\n    }\n    \n    const contextObj = context as unknown as Record<string, unknown>\n    console.log('ðŸ“„ Generating proposal for:', (contextObj.name as string | undefined) || 'Unknown')\n    \n    // Generate proposal content using AI (same logic as /api/generate-proposal)\n    const proposalPrompt = `Based on this consulting conversation, generate a personalized proposal in markdown format:\n\nCLIENT PROFILE:\n- Name: ${(contextObj.name as string | undefined) || 'Not specified'}\n- Email: ${context.email}\n- Company: ${(contextObj.company_domain as string | undefined) || 'Not specified'}\n- Industry: ${(() => {\n  const companyContext = contextObj.company_context as Record<string, unknown> | undefined\n  return typeof companyContext?.summary === 'string' ? companyContext.summary : 'Not specified'\n})()}\n- Role: ${(() => {\n  const roleContext = contextObj.role_context as Record<string, unknown> | undefined\n  return typeof roleContext?.summary === 'string' ? roleContext.summary : 'Not specified'\n})()}\n\nCONVERSATION INSIGHTS:\n- Messages exchanged: ${usage.messages_sent}\n- Voice time: ${Math.floor(usage.voice_minutes_used)} minutes\n- Screen share used: ${usage.screen_minutes_used > 0 ? 'Yes' : 'No'}\n- Research performed: ${usage.research_calls_used} queries\n\nDISCOVERED CONTEXT:\n${(() => {\n  const industryInsights = contextObj.industry_insights as Record<string, unknown> | undefined\n  return typeof industryInsights?.challenges === 'string' ? industryInsights.challenges : 'General AI consulting needs'\n})()}\n\nGenerate a professional proposal with these sections:\n\n# Your Personalized AI Strategy Proposal\n\n## Executive Summary\n- Who ${(contextObj.name as string | undefined) || 'the client'} is (based on research)\n- Key challenges we identified in our conversation\n- How F.B/c can help\n\n## Recommended Solution\nChoose one based on conversation depth:\n- **AI Strategy Workshop (1-day, in-person)** - Best for exploring AI opportunities\n- **Custom AI Implementation (4-8 weeks)** - Best for specific use case identified\n- **AI Readiness Assessment (2 weeks)** - Best for early-stage exploration\n\nInclude timeline and expected outcomes.\n\n## Your Company Context\n${(() => {\n  const companyOverview = contextObj.company_overview as Record<string, unknown> | undefined\n  return typeof companyOverview?.summary === 'string' ? companyOverview.summary : 'Brief overview based on available information'\n})()}\n\n## Next Steps\n1. Book a 30-minute strategy call: [${CONTACT_CONFIG.SCHEDULING.BOOKING_URL}](${CONTACT_CONFIG.SCHEDULING.BOOKING_URL})\n2. Email: ${CONTACT_CONFIG.SUPPORT_EMAIL}\n3. Website: ${CONTACT_CONFIG.WEBSITE_URL.replace(/^https?:\\/\\//, '')}\n\n---\n\n*This proposal was generated based on our ${usage.messages_sent}-message conversation and ${Math.floor(usage.session_duration_minutes || 0)} minutes of interaction.*\n\nFormat as clean, professional markdown. Be concise and specific.`\n\n    const model = google(GEMINI_MODELS.DEFAULT_CHAT)\n    const result = await generateText({\n      model,\n      prompt: proposalPrompt,\n      temperature: 0.7\n    })\n\n    return result.text\n  } catch (error) {\n    console.error('[generateProposal] Error:', error)\n    throw new Error(\n      error instanceof Error \n        ? `Failed to generate proposal: ${error.message}`\n        : 'Failed to generate proposal'\n    )\n  }\n}\n",
    "content2": "/**\n * Generate Proposal Tool Executor\n * \n * Generates a proposal based on conversation (wraps /api/generate-proposal logic).\n */\n\nimport { generateText, google } from '@/lib/ai-client'\nimport { CONTACT_CONFIG, GEMINI_MODELS } from '@/config/constants'\nimport { ContextStorage } from '../context/context-storage'\nimport { usageLimiter } from '@/lib/usage-limits'\n\nconst contextStorage = new ContextStorage()\n\n/**\n * Generate proposal text from conversation\n * \n * @param sessionId - Session ID to get conversation data from\n * @returns Markdown-formatted proposal text\n */\nexport async function generateProposal(sessionId: string): Promise<string> {\n  try {\n    // Get conversation context\n    const context = await contextStorage.get(sessionId)\n    const usage = await usageLimiter.getUsage(sessionId)\n    \n    if (!context || !usage) {\n      throw new Error('Session not found or no usage data available')\n    }\n    \n    const contextObj = context as unknown as Record<string, unknown>\n    console.log('ðŸ“„ Generating proposal for:', (contextObj.name as string | undefined) || 'Unknown')\n    \n    // Generate proposal content using AI (same logic as /api/generate-proposal)\n    const proposalPrompt = `Based on this consulting conversation, generate a personalized proposal in markdown format:\n\nCLIENT PROFILE:\n- Name: ${(contextObj.name as string | undefined) || 'Not specified'}\n- Email: ${context.email}\n- Company: ${(contextObj.company_domain as string | undefined) || 'Not specified'}\n- Industry: ${(() => {\n  const companyContext = contextObj.company_context as Record<string, unknown> | undefined\n  return typeof companyContext?.summary === 'string' ? companyContext.summary : 'Not specified'\n})()}\n- Role: ${(() => {\n  const roleContext = contextObj.role_context as Record<string, unknown> | undefined\n  return typeof roleContext?.summary === 'string' ? roleContext.summary : 'Not specified'\n})()}\n\nCONVERSATION INSIGHTS:\n- Messages exchanged: ${usage.messages_sent}\n- Voice time: ${Math.floor(usage.voice_minutes_used)} minutes\n- Screen share used: ${usage.screen_minutes_used > 0 ? 'Yes' : 'No'}\n- Research performed: ${usage.research_calls_used} queries\n\nDISCOVERED CONTEXT:\n${(() => {\n  const industryInsights = contextObj.industry_insights as Record<string, unknown> | undefined\n  return typeof industryInsights?.challenges === 'string' ? industryInsights.challenges : 'General AI consulting needs'\n})()}\n\nGenerate a professional proposal with these sections:\n\n# Your Personalized AI Strategy Proposal\n\n## Executive Summary\n- Who ${(contextObj.name as string | undefined) || 'the client'} is (based on research)\n- Key challenges we identified in our conversation\n- How F.B/c can help\n\n## Recommended Solution\nChoose one based on conversation depth:\n- **AI Strategy Workshop (1-day, in-person)** - Best for exploring AI opportunities\n- **Custom AI Implementation (4-8 weeks)** - Best for specific use case identified\n- **AI Readiness Assessment (2 weeks)** - Best for early-stage exploration\n\nInclude timeline and expected outcomes.\n\n## Your Company Context\n${(() => {\n  const companyOverview = contextObj.company_overview as Record<string, unknown> | undefined\n  return typeof companyOverview?.summary === 'string' ? companyOverview.summary : 'Brief overview based on available information'\n})()}\n\n## Next Steps\n1. Book a 30-minute strategy call: [${CONTACT_CONFIG.SCHEDULING.BOOKING_URL}](${CONTACT_CONFIG.SCHEDULING.BOOKING_URL})\n2. Email: ${CONTACT_CONFIG.SUPPORT_EMAIL}\n3. Website: ${CONTACT_CONFIG.WEBSITE_URL.replace(/^https?:\\/\\//, '')}\n\n---\n\n*This proposal was generated based on our ${usage.messages_sent}-message conversation and ${Math.floor(usage.session_duration_minutes || 0)} minutes of interaction.*\n\nFormat as clean, professional markdown. Be concise and specific.`\n\n    const model = google(GEMINI_MODELS.DEFAULT_CHAT)\n    const result = await generateText({\n      model,\n      prompt: proposalPrompt,\n      temperature: 0.7\n    })\n\n    return result.text\n  } catch (error) {\n    console.error('[generateProposal] Error:', error)\n    throw new Error(\n      error instanceof Error \n        ? `Failed to generate proposal: ${error.message}`\n        : 'Failed to generate proposal'\n    )\n  }\n}\n"
  },
  "tools/generate-summary-preview": {
    "status": "identical",
    "differences": [],
    "stats": {
      "source": {
        "lines": 134,
        "exports": 0,
        "functions": 2,
        "classes": 0
      },
      "target": {
        "lines": 134,
        "exports": 0,
        "functions": 2,
        "classes": 0
      }
    },
    "content1": "/**\n * Generate Summary Preview Tool Executor\n * \n * Generates a text preview of what will be included in the final PDF\n * without actually generating the PDF file.\n */\n\nimport { extractConversationInsights, buildConversationPairs } from '../pdf-generator-puppeteer.js'\nimport { multimodalContextManager } from '../../context/multimodal-context.js'\nimport { ContextStorage } from '../../context/context-storage.js'\n\nconst contextStorage = new ContextStorage()\n\ninterface SummaryPreviewOptions {\n  includeRecommendations?: boolean\n  includeNextSteps?: boolean\n}\n\n/**\n * Generate summary preview text\n * \n * @param sessionId - Session ID to get conversation data from\n * @param options - Options for what to include in preview\n * @returns Markdown-formatted preview text\n */\nexport async function generateSummaryPreview(\n  sessionId: string,\n  options: SummaryPreviewOptions = {}\n): Promise<string> {\n  try {\n    const includeRecommendations = options.includeRecommendations !== false\n    const includeNextSteps = options.includeNextSteps !== false\n\n    // Get conversation context\n    const context = await multimodalContextManager.getConversationContext(sessionId, false, false)\n    \n    // Get lead context\n    const leadContext = await contextStorage.get(sessionId)\n    const leadName = leadContext?.name || 'there'\n    const companyContext = leadContext?.company_context\n    const companyName = (companyContext && typeof companyContext === 'object' && 'name' in companyContext && typeof companyContext.name === 'string')\n      ? companyContext.name\n      : leadContext?.name || 'your company'\n\n    if (!context.conversationHistory || context.conversationHistory.length === 0) {\n      return `# Conversation Summary Preview\\n\\nNo conversation history available yet.`\n    }\n\n    // Convert ConversationEntry[] to format expected by buildConversationPairs\n    const conversationHistory = context.conversationHistory.map((entry: { metadata?: { speaker?: string }; content?: string; timestamp?: string }): { role: 'user' | 'assistant'; content: string; timestamp?: string } => {\n      const role = entry.metadata?.speaker === 'model' || entry.metadata?.speaker === 'assistant' \n        ? 'assistant' \n        : 'user'\n      \n      return {\n        role: role as 'user' | 'assistant',\n        content: entry.content || '',\n        timestamp: entry.timestamp\n      }\n    })\n\n    // Build conversation pairs and extract insights\n    const pairs = buildConversationPairs(conversationHistory)\n    const insights = extractConversationInsights(pairs)\n\n    // Build preview text\n    const sections: string[] = []\n    \n    sections.push(`# Conversation Summary Preview\\n`)\n    sections.push(`**Client:** ${leadName}`)\n    sections.push(`**Company:** ${companyName}`)\n    sections.push(`**Total Messages:** ${context.conversationHistory.length}\\n`)\n\n    // Executive Summary (from conversation history)\n    sections.push(`## Executive Summary\\n`)\n    if (pairs.length > 0) {\n      const lastPair = pairs[pairs.length - 1]\n      const summaryText = lastPair.assistant \n        ? lastPair.assistant.slice(0, 300) + (lastPair.assistant.length > 300 ? '...' : '')\n        : 'Summary of our discussion about AI strategy and implementation.'\n      sections.push(summaryText + '\\n')\n    }\n\n    // Key Outcomes & Next Steps\n    if (includeNextSteps && (insights.nextSteps.length > 0 || insights.keyDecisions.length > 0)) {\n      sections.push(`## Key Outcomes & Next Steps\\n`)\n      \n      if (insights.keyDecisions.length > 0) {\n        sections.push(`### Key Decisions`)\n        insights.keyDecisions.forEach((decision, idx) => {\n          sections.push(`${idx + 1}. ${decision}`)\n        })\n        sections.push('')\n      }\n\n      if (insights.nextSteps.length > 0) {\n        sections.push(`### Next Steps`)\n        insights.nextSteps.forEach((step, idx) => {\n          sections.push(`${idx + 1}. ${step}`)\n        })\n        sections.push('')\n      }\n    }\n\n    // Recommendations\n    if (includeRecommendations && insights.recommendations.length > 0) {\n      sections.push(`## Recommendations\\n`)\n      insights.recommendations.forEach((rec, idx) => {\n        sections.push(`${idx + 1}. ${rec}`)\n      })\n      sections.push('')\n    }\n\n    // Important Points\n    if (insights.importantPoints.length > 0) {\n      sections.push(`## Important Points Discussed\\n`)\n      insights.importantPoints.forEach((point, idx) => {\n        sections.push(`${idx + 1}. ${point}`)\n      })\n      sections.push('')\n    }\n\n    return sections.join('\\n')\n  } catch (error) {\n    console.error('[generateSummaryPreview] Error:', error)\n    throw new Error(\n      error instanceof Error \n        ? `Failed to generate summary preview: ${error.message}`\n        : 'Failed to generate summary preview'\n    )\n  }\n}\n\n",
    "content2": "/**\n * Generate Summary Preview Tool Executor\n * \n * Generates a text preview of what will be included in the final PDF\n * without actually generating the PDF file.\n */\n\nimport { extractConversationInsights, buildConversationPairs } from '../pdf-generator-puppeteer'\nimport { multimodalContextManager } from '../context/multimodal-context'\nimport { ContextStorage } from '../context/context-storage'\n\nconst contextStorage = new ContextStorage()\n\ninterface SummaryPreviewOptions {\n  includeRecommendations?: boolean\n  includeNextSteps?: boolean\n}\n\n/**\n * Generate summary preview text\n * \n * @param sessionId - Session ID to get conversation data from\n * @param options - Options for what to include in preview\n * @returns Markdown-formatted preview text\n */\nexport async function generateSummaryPreview(\n  sessionId: string,\n  options: SummaryPreviewOptions = {}\n): Promise<string> {\n  try {\n    const includeRecommendations = options.includeRecommendations !== false\n    const includeNextSteps = options.includeNextSteps !== false\n\n    // Get conversation context\n    const context = await multimodalContextManager.getConversationContext(sessionId, false, false)\n    \n    // Get lead context\n    const leadContext = await contextStorage.get(sessionId)\n    const leadName = leadContext?.name || 'there'\n    const companyContext = leadContext?.company_context\n    const companyName = (companyContext && typeof companyContext === 'object' && 'name' in companyContext && typeof companyContext.name === 'string')\n      ? companyContext.name\n      : leadContext?.name || 'your company'\n\n    if (!context.conversationHistory || context.conversationHistory.length === 0) {\n      return `# Conversation Summary Preview\\n\\nNo conversation history available yet.`\n    }\n\n    // Convert ConversationEntry[] to format expected by buildConversationPairs\n    const conversationHistory = context.conversationHistory.map(entry => {\n      const role = entry.metadata?.speaker === 'model' || entry.metadata?.speaker === 'assistant' \n        ? 'assistant' \n        : 'user'\n      \n      return {\n        role: role as 'user' | 'assistant',\n        content: entry.content || '',\n        timestamp: entry.timestamp\n      }\n    })\n\n    // Build conversation pairs and extract insights\n    const pairs = buildConversationPairs(conversationHistory)\n    const insights = extractConversationInsights(pairs)\n\n    // Build preview text\n    const sections: string[] = []\n    \n    sections.push(`# Conversation Summary Preview\\n`)\n    sections.push(`**Client:** ${leadName}`)\n    sections.push(`**Company:** ${companyName}`)\n    sections.push(`**Total Messages:** ${context.conversationHistory.length}\\n`)\n\n    // Executive Summary (from conversation history)\n    sections.push(`## Executive Summary\\n`)\n    if (pairs.length > 0) {\n      const lastPair = pairs[pairs.length - 1]\n      const summaryText = lastPair.assistant?.content \n        ? lastPair.assistant.content.slice(0, 300) + (lastPair.assistant.content.length > 300 ? '...' : '')\n        : 'Summary of our discussion about AI strategy and implementation.'\n      sections.push(summaryText + '\\n')\n    }\n\n    // Key Outcomes & Next Steps\n    if (includeNextSteps && (insights.nextSteps.length > 0 || insights.keyDecisions.length > 0)) {\n      sections.push(`## Key Outcomes & Next Steps\\n`)\n      \n      if (insights.keyDecisions.length > 0) {\n        sections.push(`### Key Decisions`)\n        insights.keyDecisions.forEach((decision, idx) => {\n          sections.push(`${idx + 1}. ${decision}`)\n        })\n        sections.push('')\n      }\n\n      if (insights.nextSteps.length > 0) {\n        sections.push(`### Next Steps`)\n        insights.nextSteps.forEach((step, idx) => {\n          sections.push(`${idx + 1}. ${step}`)\n        })\n        sections.push('')\n      }\n    }\n\n    // Recommendations\n    if (includeRecommendations && insights.recommendations.length > 0) {\n      sections.push(`## Recommendations\\n`)\n      insights.recommendations.forEach((rec, idx) => {\n        sections.push(`${idx + 1}. ${rec}`)\n      })\n      sections.push('')\n    }\n\n    // Important Points\n    if (insights.importantPoints.length > 0) {\n      sections.push(`## Important Points Discussed\\n`)\n      insights.importantPoints.forEach((point, idx) => {\n        sections.push(`${idx + 1}. ${point}`)\n      })\n      sections.push('')\n    }\n\n    return sections.join('\\n')\n  } catch (error) {\n    console.error('[generateSummaryPreview] Error:', error)\n    throw new Error(\n      error instanceof Error \n        ? `Failed to generate summary preview: ${error.message}`\n        : 'Failed to generate summary preview'\n    )\n  }\n}\n\n"
  },
  "tools/shared-tool-registry": {
    "status": "identical",
    "differences": [],
    "stats": {
      "source": {
        "lines": 150,
        "exports": 1,
        "functions": 4,
        "classes": 0
      },
      "target": {
        "lines": 150,
        "exports": 1,
        "functions": 4,
        "classes": 0
      }
    },
    "content1": "import { z } from 'zod'\n\nimport { SHARED_TOOL_NAMES, type SharedToolName } from './shared-tools.js'\nimport { extractActionItems } from './extract-action-items.js'\nimport { generateSummaryPreview } from './generate-summary-preview.js'\nimport { calculateROI } from './calculate-roi.js'\nimport { draftFollowUpEmail } from './draft-follow-up-email.js'\nimport { generateProposal } from './generate-proposal.js'\n\ntype ToolSchema = z.ZodTypeAny\n\ntype SharedToolDefinition = {\n  description: string\n  inputSchema: ToolSchema\n  execute: (sessionId: string, args: unknown) => Promise<unknown>\n}\n\nconst parseNumericOptional = () =>\n  z.preprocess((value) => {\n    if (value === null || value === undefined || value === '') return undefined\n    if (typeof value === 'number') return Number.isFinite(value) ? value : undefined\n    if (typeof value === 'string') {\n      const trimmed = value.trim()\n      if (!trimmed) return undefined\n      const parsed = Number(trimmed)\n      return Number.isFinite(parsed) ? parsed : undefined\n    }\n    return undefined\n  }, z.number().optional())\n\nconst parseBooleanOptional = () =>\n  z.preprocess((value) => {\n    if (value === null || value === undefined) return undefined\n    if (typeof value === 'boolean') return value\n    if (typeof value === 'string') {\n      const normalized = value.trim().toLowerCase()\n      if (normalized === 'true') return true\n      if (normalized === 'false') return false\n    }\n    return value\n  }, z.boolean().optional())\n\nconst extractActionItemsSchema = z.object({})\n\nconst summaryPreviewSchema = z.object({\n  includeRecommendations: parseBooleanOptional().describe('Include recommendations section in preview.'),\n  includeNextSteps: parseBooleanOptional().describe('Include next steps section in preview.')\n})\n\nconst calculateRoiSchema = z.object({\n  currentCost: parseNumericOptional().describe('Current annual cost (optional, for simplified calculation).'),\n  timeSavings: parseNumericOptional().describe('Hours saved per year (optional, for simplified calculation).'),\n  employeeCostPerHour: parseNumericOptional().describe('Average employee cost per hour (optional, for simplified calculation).'),\n  implementationCost: parseNumericOptional().describe('One-time implementation cost (optional, for simplified calculation).'),\n  timeline: parseNumericOptional().describe('Timeline in months (optional).'),\n  initialInvestment: parseNumericOptional().describe('Initial investment amount (optional, for detailed calculation).'),\n  annualCost: parseNumericOptional().describe('Annual recurring cost (optional, for detailed calculation).'),\n  staffReductionSavings: parseNumericOptional().describe('Savings from staff reduction (optional, for detailed calculation).'),\n  efficiencySavings: parseNumericOptional().describe('Savings from efficiency gains (optional, for detailed calculation).'),\n  retentionSavings: parseNumericOptional().describe('Savings from retention improvement (optional, for detailed calculation).')\n})\n\nconst draftFollowUpEmailSchema = z.object({\n  recipient: z.enum(['client', 'team', 'farzad']).describe('Who the email is for.'),\n  tone: z.enum(['professional', 'casual', 'technical']).describe('Tone of the email.'),\n  includeSummary: parseBooleanOptional().describe('Include conversation summary in the email.')\n})\n\nconst generateProposalSchema = z.object({})\n\nconst sharedToolDefinitions: Record<SharedToolName, SharedToolDefinition> = {\n  extract_action_items: {\n    description: 'Extract key outcomes, recommendations, and next steps from the conversation so far.',\n    inputSchema: extractActionItemsSchema,\n    execute: async (sessionId) => {\n      return await extractActionItems(sessionId)\n    }\n  },\n  generate_summary_preview: {\n    description: 'Generate a preview of the conversation summary that will be included in the final PDF.',\n    inputSchema: summaryPreviewSchema,\n    execute: async (sessionId, args) => {\n      const parsed = summaryPreviewSchema.parse(args)\n      const preview = await generateSummaryPreview(sessionId, {\n        includeRecommendations: parsed.includeRecommendations !== false,\n        includeNextSteps: parsed.includeNextSteps !== false\n      })\n\n      return { preview }\n    }\n  },\n  calculate_roi: {\n    description: 'Calculate ROI based on discussed investment and savings. Use when discussing costs, savings, or ROI during the conversation.',\n    inputSchema: calculateRoiSchema,\n    execute: async (sessionId, args) => {\n      const parsed = calculateRoiSchema.parse(args)\n      return await calculateROI(sessionId, parsed)\n    }\n  },\n  draft_follow_up_email: {\n    description: 'Draft a follow-up email summarizing the conversation or next steps. Can be sent to the client, their team, or Farzad.',\n    inputSchema: draftFollowUpEmailSchema,\n    execute: async (sessionId, args) => {\n      const parsed = draftFollowUpEmailSchema.parse(args)\n      return await draftFollowUpEmail(sessionId, {\n        recipient: parsed.recipient,\n        tone: parsed.tone,\n        includeSummary: parsed.includeSummary !== false\n      })\n    }\n  },\n  generate_proposal_draft: {\n    description: 'Generate a proposal based on the conversation. Returns markdown proposal text that can be displayed or saved.',\n    inputSchema: generateProposalSchema,\n    execute: async (sessionId) => {\n      const proposal = await generateProposal(sessionId)\n      return { proposal }\n    }\n  }\n}\n\ntype SharedToolMapEntry = {\n  description: string\n  inputSchema: ToolSchema\n  execute: (args: unknown) => Promise<unknown>\n}\n\nexport function createSharedToolMap(sessionId: string) {\n  const map: Partial<Record<SharedToolName, SharedToolMapEntry>> = {}\n\n  for (const name of SHARED_TOOL_NAMES) {\n    const definition = sharedToolDefinitions[name]\n    map[name] = {\n      description: definition.description,\n      inputSchema: definition.inputSchema,\n      execute: (args: unknown) => definition.execute(sessionId, args)\n    }\n  }\n\n  return map as Record<SharedToolName, SharedToolMapEntry>\n}\n\nexport async function executeSharedTool(toolName: SharedToolName, sessionId: string, args: unknown) {\n  const definition = sharedToolDefinitions[toolName]\n  if (!definition) {\n    throw new Error(`Unsupported tool: ${toolName}`)\n  }\n  return await definition.execute(sessionId, args)\n}\n",
    "content2": "import { z } from 'zod'\n\nimport { SHARED_TOOL_NAMES, type SharedToolName } from './shared-tools'\nimport { extractActionItems } from './extract-action-items'\nimport { generateSummaryPreview } from './generate-summary-preview'\nimport { calculateROI } from './calculate-roi'\nimport { draftFollowUpEmail } from './draft-follow-up-email'\nimport { generateProposal } from './generate-proposal'\n\ntype ToolSchema = z.ZodTypeAny\n\ntype SharedToolDefinition = {\n  description: string\n  inputSchema: ToolSchema\n  execute: (sessionId: string, args: unknown) => Promise<unknown>\n}\n\nconst parseNumericOptional = () =>\n  z.preprocess((value) => {\n    if (value === null || value === undefined || value === '') return undefined\n    if (typeof value === 'number') return Number.isFinite(value) ? value : undefined\n    if (typeof value === 'string') {\n      const trimmed = value.trim()\n      if (!trimmed) return undefined\n      const parsed = Number(trimmed)\n      return Number.isFinite(parsed) ? parsed : undefined\n    }\n    return undefined\n  }, z.number().optional())\n\nconst parseBooleanOptional = () =>\n  z.preprocess((value) => {\n    if (value === null || value === undefined) return undefined\n    if (typeof value === 'boolean') return value\n    if (typeof value === 'string') {\n      const normalized = value.trim().toLowerCase()\n      if (normalized === 'true') return true\n      if (normalized === 'false') return false\n    }\n    return value\n  }, z.boolean().optional())\n\nconst extractActionItemsSchema = z.object({})\n\nconst summaryPreviewSchema = z.object({\n  includeRecommendations: parseBooleanOptional().describe('Include recommendations section in preview.'),\n  includeNextSteps: parseBooleanOptional().describe('Include next steps section in preview.')\n})\n\nconst calculateRoiSchema = z.object({\n  currentCost: parseNumericOptional().describe('Current annual cost (optional, for simplified calculation).'),\n  timeSavings: parseNumericOptional().describe('Hours saved per year (optional, for simplified calculation).'),\n  employeeCostPerHour: parseNumericOptional().describe('Average employee cost per hour (optional, for simplified calculation).'),\n  implementationCost: parseNumericOptional().describe('One-time implementation cost (optional, for simplified calculation).'),\n  timeline: parseNumericOptional().describe('Timeline in months (optional).'),\n  initialInvestment: parseNumericOptional().describe('Initial investment amount (optional, for detailed calculation).'),\n  annualCost: parseNumericOptional().describe('Annual recurring cost (optional, for detailed calculation).'),\n  staffReductionSavings: parseNumericOptional().describe('Savings from staff reduction (optional, for detailed calculation).'),\n  efficiencySavings: parseNumericOptional().describe('Savings from efficiency gains (optional, for detailed calculation).'),\n  retentionSavings: parseNumericOptional().describe('Savings from retention improvement (optional, for detailed calculation).')\n})\n\nconst draftFollowUpEmailSchema = z.object({\n  recipient: z.enum(['client', 'team', 'farzad']).describe('Who the email is for.'),\n  tone: z.enum(['professional', 'casual', 'technical']).describe('Tone of the email.'),\n  includeSummary: parseBooleanOptional().describe('Include conversation summary in the email.')\n})\n\nconst generateProposalSchema = z.object({})\n\nconst sharedToolDefinitions: Record<SharedToolName, SharedToolDefinition> = {\n  extract_action_items: {\n    description: 'Extract key outcomes, recommendations, and next steps from the conversation so far.',\n    inputSchema: extractActionItemsSchema,\n    execute: async (sessionId) => {\n      return await extractActionItems(sessionId)\n    }\n  },\n  generate_summary_preview: {\n    description: 'Generate a preview of the conversation summary that will be included in the final PDF.',\n    inputSchema: summaryPreviewSchema,\n    execute: async (sessionId, args) => {\n      const parsed = summaryPreviewSchema.parse(args)\n      const preview = await generateSummaryPreview(sessionId, {\n        includeRecommendations: parsed.includeRecommendations !== false,\n        includeNextSteps: parsed.includeNextSteps !== false\n      })\n\n      return { preview }\n    }\n  },\n  calculate_roi: {\n    description: 'Calculate ROI based on discussed investment and savings. Use when discussing costs, savings, or ROI during the conversation.',\n    inputSchema: calculateRoiSchema,\n    execute: async (sessionId, args) => {\n      const parsed = calculateRoiSchema.parse(args)\n      return await calculateROI(sessionId, parsed)\n    }\n  },\n  draft_follow_up_email: {\n    description: 'Draft a follow-up email summarizing the conversation or next steps. Can be sent to the client, their team, or Farzad.',\n    inputSchema: draftFollowUpEmailSchema,\n    execute: async (sessionId, args) => {\n      const parsed = draftFollowUpEmailSchema.parse(args)\n      return await draftFollowUpEmail(sessionId, {\n        recipient: parsed.recipient,\n        tone: parsed.tone,\n        includeSummary: parsed.includeSummary !== false\n      })\n    }\n  },\n  generate_proposal_draft: {\n    description: 'Generate a proposal based on the conversation. Returns markdown proposal text that can be displayed or saved.',\n    inputSchema: generateProposalSchema,\n    execute: async (sessionId) => {\n      const proposal = await generateProposal(sessionId)\n      return { proposal }\n    }\n  }\n}\n\ntype SharedToolMapEntry = {\n  description: string\n  inputSchema: ToolSchema\n  execute: (args: unknown) => Promise<unknown>\n}\n\nexport function createSharedToolMap(sessionId: string) {\n  const map: Partial<Record<SharedToolName, SharedToolMapEntry>> = {}\n\n  for (const name of SHARED_TOOL_NAMES) {\n    const definition = sharedToolDefinitions[name]\n    map[name] = {\n      description: definition.description,\n      inputSchema: definition.inputSchema,\n      execute: (args: unknown) => definition.execute(sessionId, args)\n    }\n  }\n\n  return map as Record<SharedToolName, SharedToolMapEntry>\n}\n\nexport async function executeSharedTool(toolName: SharedToolName, sessionId: string, args: unknown) {\n  const definition = sharedToolDefinitions[toolName]\n  if (!definition) {\n    throw new Error(`Unsupported tool: ${toolName}`)\n  }\n  return await definition.execute(sessionId, args)\n}\n"
  },
  "tools/shared-tools": {
    "status": "identical",
    "differences": [],
    "stats": {
      "source": {
        "lines": 14,
        "exports": 3,
        "functions": 1,
        "classes": 0
      },
      "target": {
        "lines": 14,
        "exports": 3,
        "functions": 1,
        "classes": 0
      }
    },
    "content1": "export const SHARED_TOOL_NAMES = [\n  'extract_action_items',\n  'generate_summary_preview',\n  'calculate_roi',\n  'draft_follow_up_email',\n  'generate_proposal_draft'\n] as const\n\nexport type SharedToolName = typeof SHARED_TOOL_NAMES[number]\n\nexport function isSharedToolName(value: unknown): value is SharedToolName {\n  return typeof value === 'string' && (SHARED_TOOL_NAMES as readonly string[]).includes(value)\n}\n",
    "content2": "export const SHARED_TOOL_NAMES = [\n  'extract_action_items',\n  'generate_summary_preview',\n  'calculate_roi',\n  'draft_follow_up_email',\n  'generate_proposal_draft'\n] as const\n\nexport type SharedToolName = typeof SHARED_TOOL_NAMES[number]\n\nexport function isSharedToolName(value: unknown): value is SharedToolName {\n  return typeof value === 'string' && (SHARED_TOOL_NAMES as readonly string[]).includes(value)\n}\n"
  },
  "tools/tool-executor": {
    "status": "identical",
    "differences": [],
    "stats": {
      "source": {
        "lines": 272,
        "exports": 2,
        "functions": 1,
        "classes": 1
      },
      "target": {
        "lines": 272,
        "exports": 2,
        "functions": 1,
        "classes": 1
      }
    },
    "content1": "import { vercelCache } from '../../lib/vercel-cache.js'\nimport { auditLog } from '../security/audit-logger.js'\nimport { retry } from '../../utils/code-quality.js'\nimport type { ToolExecutionResult } from './types.js'\n\n/**\n * Tool Executor - Unified tool execution layer with logging, retry, and caching\n * \n * Wraps AI SDK tool calls to provide:\n * - Execution logging to audit_log\n * - Retry logic for transient failures\n * - Redis caching for idempotent operations\n * - Performance metrics\n */\nexport class ToolExecutor {\n  private maxRetries: number\n  private cacheEnabled: boolean\n  private cacheTTL: number // milliseconds\n\n  constructor(options: {\n    maxRetries?: number\n    cacheEnabled?: boolean\n    cacheTTL?: number\n  } = {}) {\n    this.maxRetries = options.maxRetries ?? parseInt(process.env.TOOL_RETRY_MAX || '3', 10)\n    this.cacheEnabled = options.cacheEnabled ?? (process.env.ENABLE_TOOL_CACHING === 'true')\n    this.cacheTTL = options.cacheTTL ?? 5 * 60 * 1000 // 5 minutes default\n  }\n\n  /**\n   * Execute a tool with logging, retry, and caching\n   */\n  async execute<T = unknown>(params: {\n    toolName: string\n    sessionId: string\n    agent: string\n    inputs: Record<string, unknown>\n    handler: () => Promise<T>\n    cacheable?: boolean // Whether this tool result can be cached\n  }): Promise<ToolExecutionResult<T>> {\n    const { toolName, sessionId, agent, inputs, handler, cacheable = false } = params\n    const startTime = Date.now()\n    let attemptCount = 0\n    let lastError: Error | null = null\n\n    // Generate cache key for cacheable tools\n    const cacheKey = cacheable && this.cacheEnabled\n      ? this.generateCacheKey(toolName, inputs)\n      : null\n\n    // Check cache first (if cacheable)\n    if (cacheKey) {\n      try {\n        const cachedResult = await vercelCache.get<T>('tool-execution', cacheKey)\n        if (cachedResult !== null) {\n          const duration = Date.now() - startTime\n          \n          // Log cache hit (non-blocking)\n          this.logExecution({\n            toolName,\n            sessionId,\n            agent,\n            inputs,\n            outputs: cachedResult,\n            duration,\n            success: true,\n            cached: true,\n            attempt: 0\n          }).catch(err => console.warn('Tool execution audit log failed (non-fatal):', err))\n\n          return {\n            success: true,\n            data: cachedResult,\n            duration,\n            cached: true,\n            attempt: 0\n          }\n        }\n      } catch (err) {\n        console.warn(`[ToolExecutor] Cache check failed for ${toolName}:`, err)\n        // Continue with execution - cache failure shouldn't block\n      }\n    }\n\n    // Retry logic with caching and logging wrapper\n    // Wrap handler to include caching logic and track attempts\n    const wrappedHandler = async (): Promise<T> => {\n      attemptCount++\n      const result = await handler()\n      \n      // Cache successful result (if cacheable)\n      if (cacheKey && this.cacheEnabled) {\n        try {\n          await vercelCache.set('tool-execution', cacheKey, result, {\n            ttl: this.cacheTTL\n          })\n        } catch (err) {\n          console.warn(`[ToolExecutor] Cache set failed for ${toolName}:`, err)\n          // Continue - caching failure shouldn't block\n        }\n      }\n      \n      return result\n    }\n\n    try {\n      const result = await retry(\n        wrappedHandler,\n        this.maxRetries,\n        1000, // Initial delay: 1s\n        2, // Backoff multiplier\n        // Only retry transient errors\n        (error) => this.isTransientError(error)\n      )\n      \n      const duration = Date.now() - startTime\n\n      // Log successful execution (non-blocking)\n      this.logExecution({\n        toolName,\n        sessionId,\n        agent,\n        inputs,\n        outputs: result,\n        duration,\n        success: true,\n        cached: false,\n        attempt: attemptCount\n      }).catch(err => console.warn('Tool execution audit log failed (non-fatal):', err))\n\n      return {\n        success: true,\n        data: result,\n        duration,\n        cached: false,\n        attempt: attemptCount\n      }\n    } catch (error: unknown) {\n      lastError = error instanceof Error ? error : new Error(String(error))\n    }\n\n    // All retries exhausted\n    const duration = Date.now() - startTime\n    const errorMessage = lastError?.message || 'Unknown error'\n\n    // Log failure (non-blocking)\n    this.logExecution({\n      toolName,\n      sessionId,\n      agent,\n      inputs,\n      outputs: undefined,\n      duration,\n      success: false,\n      cached: false,\n      attempt: attemptCount,\n      error: errorMessage\n    }).catch(err => console.warn('Tool execution audit log failed (non-fatal):', err))\n\n    return {\n      success: false,\n      error: errorMessage,\n      duration,\n      cached: false,\n      attempt: attemptCount\n    }\n  }\n\n  /**\n   * Generate cache key from tool name and inputs\n   */\n  private generateCacheKey(toolName: string, inputs: Record<string, unknown>): string {\n    // Sort keys for consistent hashing\n    const sortedInputs = Object.keys(inputs)\n      .sort()\n      .reduce((acc, key) => {\n        acc[key] = inputs[key]\n        return acc\n      }, {} as Record<string, unknown>)\n    \n    return `${toolName}:${JSON.stringify(sortedInputs)}`\n  }\n\n  /**\n   * Check if error is transient (should retry)\n   */\n  private isTransientError(error: unknown): boolean {\n    if (!(error instanceof Error)) return false\n\n    const message = error.message.toLowerCase()\n    const transientPatterns = [\n      'network',\n      'timeout',\n      'econnreset',\n      'enotfound',\n      'econnrefused',\n      'temporary',\n      'rate limit',\n      '429',\n      '503',\n      '502'\n    ]\n\n    return transientPatterns.some(pattern => message.includes(pattern))\n  }\n\n  /**\n   * Log tool execution to audit_log (non-blocking)\n   */\n  private async logExecution(params: {\n    toolName: string\n    sessionId: string\n    agent: string\n    inputs: Record<string, unknown>\n    outputs?: unknown\n    duration: number\n    success: boolean\n    cached: boolean\n    attempt: number\n    error?: string\n  }): Promise<void> {\n    // Only log if audit is enabled\n    if (process.env.NODE_ENV !== 'production' && process.env.ENABLE_AGENT_AUDIT !== 'true') {\n      return\n    }\n\n    try {\n      await auditLog.logToolExecution(\n        params.sessionId || 'anonymous',\n        params.toolName,\n        params.agent,\n        {\n          duration: params.duration,\n          success: params.success,\n          error: params.error\n        },\n        {\n          inputs: this.sanitizeData(params.inputs),\n          outputs: params.outputs ? this.sanitizeData(params.outputs) : undefined,\n          cached: params.cached,\n          attempt: params.attempt\n        }\n      )\n    } catch (err) {\n      // Silent failure - don't block tool execution\n      console.warn('[ToolExecutor] Audit logging failed:', err)\n    }\n  }\n\n  /**\n   * Sanitize data for logging (remove PII, limit size)\n   */\n  private sanitizeData(data: unknown): Record<string, unknown> | undefined {\n    if (data === null || data === undefined) return undefined\n    if (typeof data !== 'object') return undefined\n\n    // Limit object depth and size\n    const maxSize = 1000 // characters\n    const jsonStr = JSON.stringify(data)\n    \n    if (jsonStr.length > maxSize) {\n      return { _truncated: true, _size: jsonStr.length }\n    }\n\n    // Return as Record, assuming it's a plain object\n    return data as Record<string, unknown>\n  }\n}\n\nexport const toolExecutor = new ToolExecutor()\n\n",
    "content2": "import { vercelCache } from '@/lib/vercel-cache'\nimport { auditLog } from '@/core/security/audit-logger'\nimport { retry } from '@/lib/code-quality'\nimport type { ToolExecutionResult } from './types'\n\n/**\n * Tool Executor - Unified tool execution layer with logging, retry, and caching\n * \n * Wraps AI SDK tool calls to provide:\n * - Execution logging to audit_log\n * - Retry logic for transient failures\n * - Redis caching for idempotent operations\n * - Performance metrics\n */\nexport class ToolExecutor {\n  private maxRetries: number\n  private cacheEnabled: boolean\n  private cacheTTL: number // milliseconds\n\n  constructor(options: {\n    maxRetries?: number\n    cacheEnabled?: boolean\n    cacheTTL?: number\n  } = {}) {\n    this.maxRetries = options.maxRetries ?? parseInt(process.env.TOOL_RETRY_MAX || '3', 10)\n    this.cacheEnabled = options.cacheEnabled ?? (process.env.ENABLE_TOOL_CACHING === 'true')\n    this.cacheTTL = options.cacheTTL ?? 5 * 60 * 1000 // 5 minutes default\n  }\n\n  /**\n   * Execute a tool with logging, retry, and caching\n   */\n  async execute<T = unknown>(params: {\n    toolName: string\n    sessionId: string\n    agent: string\n    inputs: Record<string, unknown>\n    handler: () => Promise<T>\n    cacheable?: boolean // Whether this tool result can be cached\n  }): Promise<ToolExecutionResult<T>> {\n    const { toolName, sessionId, agent, inputs, handler, cacheable = false } = params\n    const startTime = Date.now()\n    let attemptCount = 0\n    let lastError: Error | null = null\n\n    // Generate cache key for cacheable tools\n    const cacheKey = cacheable && this.cacheEnabled\n      ? this.generateCacheKey(toolName, inputs)\n      : null\n\n    // Check cache first (if cacheable)\n    if (cacheKey) {\n      try {\n        const cachedResult = await vercelCache.get<T>('tool-execution', cacheKey)\n        if (cachedResult !== null) {\n          const duration = Date.now() - startTime\n          \n          // Log cache hit (non-blocking)\n          this.logExecution({\n            toolName,\n            sessionId,\n            agent,\n            inputs,\n            outputs: cachedResult,\n            duration,\n            success: true,\n            cached: true,\n            attempt: 0\n          }).catch(err => console.warn('Tool execution audit log failed (non-fatal):', err))\n\n          return {\n            success: true,\n            data: cachedResult,\n            duration,\n            cached: true,\n            attempt: 0\n          }\n        }\n      } catch (err) {\n        console.warn(`[ToolExecutor] Cache check failed for ${toolName}:`, err)\n        // Continue with execution - cache failure shouldn't block\n      }\n    }\n\n    // Retry logic with caching and logging wrapper\n    // Wrap handler to include caching logic and track attempts\n    const wrappedHandler = async (): Promise<T> => {\n      attemptCount++\n      const result = await handler()\n      \n      // Cache successful result (if cacheable)\n      if (cacheKey && this.cacheEnabled) {\n        try {\n          await vercelCache.set('tool-execution', cacheKey, result, {\n            ttl: this.cacheTTL\n          })\n        } catch (err) {\n          console.warn(`[ToolExecutor] Cache set failed for ${toolName}:`, err)\n          // Continue - caching failure shouldn't block\n        }\n      }\n      \n      return result\n    }\n\n    try {\n      const result = await retry(\n        wrappedHandler,\n        this.maxRetries,\n        1000, // Initial delay: 1s\n        2, // Backoff multiplier\n        // Only retry transient errors\n        (error) => this.isTransientError(error)\n      )\n      \n      const duration = Date.now() - startTime\n\n      // Log successful execution (non-blocking)\n      this.logExecution({\n        toolName,\n        sessionId,\n        agent,\n        inputs,\n        outputs: result,\n        duration,\n        success: true,\n        cached: false,\n        attempt: attemptCount\n      }).catch(err => console.warn('Tool execution audit log failed (non-fatal):', err))\n\n      return {\n        success: true,\n        data: result,\n        duration,\n        cached: false,\n        attempt: attemptCount\n      }\n    } catch (error) {\n      lastError = error instanceof Error ? error : new Error(String(error))\n    }\n\n    // All retries exhausted\n    const duration = Date.now() - startTime\n    const errorMessage = lastError?.message || 'Unknown error'\n\n    // Log failure (non-blocking)\n    this.logExecution({\n      toolName,\n      sessionId,\n      agent,\n      inputs,\n      outputs: undefined,\n      duration,\n      success: false,\n      cached: false,\n      attempt: attemptCount,\n      error: errorMessage\n    }).catch(err => console.warn('Tool execution audit log failed (non-fatal):', err))\n\n    return {\n      success: false,\n      error: errorMessage,\n      duration,\n      cached: false,\n      attempt: attemptCount\n    }\n  }\n\n  /**\n   * Generate cache key from tool name and inputs\n   */\n  private generateCacheKey(toolName: string, inputs: Record<string, unknown>): string {\n    // Sort keys for consistent hashing\n    const sortedInputs = Object.keys(inputs)\n      .sort()\n      .reduce((acc, key) => {\n        acc[key] = inputs[key]\n        return acc\n      }, {} as Record<string, unknown>)\n    \n    return `${toolName}:${JSON.stringify(sortedInputs)}`\n  }\n\n  /**\n   * Check if error is transient (should retry)\n   */\n  private isTransientError(error: unknown): boolean {\n    if (!(error instanceof Error)) return false\n\n    const message = error.message.toLowerCase()\n    const transientPatterns = [\n      'network',\n      'timeout',\n      'econnreset',\n      'enotfound',\n      'econnrefused',\n      'temporary',\n      'rate limit',\n      '429',\n      '503',\n      '502'\n    ]\n\n    return transientPatterns.some(pattern => message.includes(pattern))\n  }\n\n  /**\n   * Log tool execution to audit_log (non-blocking)\n   */\n  private async logExecution(params: {\n    toolName: string\n    sessionId: string\n    agent: string\n    inputs: Record<string, unknown>\n    outputs?: unknown\n    duration: number\n    success: boolean\n    cached: boolean\n    attempt: number\n    error?: string\n  }): Promise<void> {\n    // Only log if audit is enabled\n    if (process.env.NODE_ENV !== 'production' && process.env.ENABLE_AGENT_AUDIT !== 'true') {\n      return\n    }\n\n    try {\n      await auditLog.logToolExecution(\n        params.sessionId || 'anonymous',\n        params.toolName,\n        params.agent,\n        {\n          duration: params.duration,\n          success: params.success,\n          error: params.error\n        },\n        {\n          inputs: this.sanitizeData(params.inputs),\n          outputs: params.outputs ? this.sanitizeData(params.outputs) : undefined,\n          cached: params.cached,\n          attempt: params.attempt\n        }\n      )\n    } catch (err) {\n      // Silent failure - don't block tool execution\n      console.warn('[ToolExecutor] Audit logging failed:', err)\n    }\n  }\n\n  /**\n   * Sanitize data for logging (remove PII, limit size)\n   */\n  private sanitizeData(data: unknown): Record<string, unknown> | undefined {\n    if (data === null || data === undefined) return undefined\n    if (typeof data !== 'object') return undefined\n\n    // Limit object depth and size\n    const maxSize = 1000 // characters\n    const jsonStr = JSON.stringify(data)\n    \n    if (jsonStr.length > maxSize) {\n      return { _truncated: true, _size: jsonStr.length }\n    }\n\n    // Return as Record, assuming it's a plain object\n    return data as Record<string, unknown>\n  }\n}\n\nexport const toolExecutor = new ToolExecutor()\n\n"
  },
  "tools/tool-types": {
    "status": "identical",
    "differences": [],
    "stats": {
      "source": {
        "lines": 27,
        "exports": 3,
        "functions": 0,
        "classes": 0
      },
      "target": {
        "lines": 27,
        "exports": 3,
        "functions": 0,
        "classes": 0
      }
    },
    "content1": "/**\n * Type definitions for PDF generator tool call results\n */\n\nexport interface ActionItemsResult {\n  recommendations: string[]\n  nextSteps: string[]\n  keyDecisions: string[]\n  importantPoints: string[]\n}\n\nexport interface ROICalculationResult {\n  paybackPeriod: string\n  firstYearROI: number\n  threeYearROI: number\n  roiPercentage: number\n  totalInvestment: number\n  totalSavings: number\n}\n\nexport interface EmailDraftResult {\n  subject: string\n  body: string\n  cta: string\n}\n\n",
    "content2": "/**\n * Type definitions for PDF generator tool call results\n */\n\nexport interface ActionItemsResult {\n  recommendations: string[]\n  nextSteps: string[]\n  keyDecisions: string[]\n  importantPoints: string[]\n}\n\nexport interface ROICalculationResult {\n  paybackPeriod: string\n  firstYearROI: number\n  threeYearROI: number\n  roiPercentage: number\n  totalInvestment: number\n  totalSavings: number\n}\n\nexport interface EmailDraftResult {\n  subject: string\n  body: string\n  cta: string\n}\n\n"
  },
  "tools/types": {
    "status": "identical",
    "differences": [],
    "stats": {
      "source": {
        "lines": 20,
        "exports": 2,
        "functions": 0,
        "classes": 0
      },
      "target": {
        "lines": 20,
        "exports": 2,
        "functions": 0,
        "classes": 0
      }
    },
    "content1": "/**\n * Types for tool execution layer\n */\n\nexport interface ToolExecutionResult<T = unknown> {\n  success: boolean\n  data?: T\n  error?: string\n  duration: number\n  cached: boolean\n  attempt: number\n}\n\nexport interface ToolExecutionOptions {\n  maxRetries?: number\n  cacheEnabled?: boolean\n  cacheTTL?: number\n}\n\n",
    "content2": "/**\n * Types for tool execution layer\n */\n\nexport interface ToolExecutionResult<T = unknown> {\n  success: boolean\n  data?: T\n  error?: string\n  duration: number\n  cached: boolean\n  attempt: number\n}\n\nexport interface ToolExecutionOptions {\n  maxRetries?: number\n  cacheEnabled?: boolean\n  cacheTTL?: number\n}\n\n"
  },
  "context/multimodal-context": {
    "status": "file2_missing",
    "differences": [
      "File 2 does not exist"
    ]
  },
  "context/context-storage": {
    "status": "identical",
    "differences": [],
    "stats": {
      "source": {
        "lines": 519,
        "exports": 2,
        "functions": 1,
        "classes": 1
      },
      "target": {
        "lines": 519,
        "exports": 2,
        "functions": 1,
        "classes": 1
      }
    },
    "content1": "import { getSupabaseService } from '../lib/supabase.js'\nimport { DatabaseConversationContext } from './context-types.js'\nimport { asContexts } from '../lib/supabase-parsers.js'\nimport type { Database, Json } from '../supabase/database.types.js'\nimport { toJson } from '../types/json-guards.js'\nimport { calculateBackoffDelay, DEFAULT_BACKOFF_MULTIPLIER } from '../lib/ai/retry-config.js'\n\ntype ConversationContextExtendedFields = {\n  metadata?: Json | null\n  conversation_flow?: Json | null\n  intelligence_context?: Json | null\n  last_agent?: string | null\n  last_stage?: string | null\n  event_id?: string | null\n  analytics_pending?: boolean | null\n  version?: number | null\n  pdf_url?: string | null\n  pdf_generated_at?: string | null\n}\n\ntype ConversationContextInsert = Database['public']['Tables']['conversation_contexts']['Insert'] & ConversationContextExtendedFields\ntype ConversationContextUpdate = Database['public']['Tables']['conversation_contexts']['Update'] & ConversationContextExtendedFields\n\nconst resolveJsonField = (\n  incoming: unknown | null | undefined,\n  existing: unknown | null | undefined\n): Json | null | undefined => {\n  if (incoming !== undefined) {\n    if (incoming === null) return null\n    try {\n      return toJson(incoming)\n    } catch {\n      // If toJson fails (e.g., value is undefined or invalid), return undefined to skip the field\n      return undefined\n    }\n  }\n  if (existing !== undefined) {\n    if (existing === null) return null\n    try {\n      return toJson(existing)\n    } catch {\n      // If toJson fails (e.g., value is undefined or invalid), return undefined to skip the field\n      return undefined\n    }\n  }\n  return undefined\n}\n\n// Browser-safe logger (winston is Node.js only)\nconst logger = {\n  warn: console.warn.bind(console),\n  error: console.error.bind(console),\n  debug: console.debug.bind(console),\n  info: console.info.bind(console),\n}\n\nexport class ContextStorage {\n  // Use the service client type to avoid Database generic issues.\n  private supabase: ReturnType<typeof getSupabaseService> | null\n  private inMemoryStorage: Map<string, DatabaseConversationContext>\n  private cacheTimestamps: Map<string, number>\n  private readonly CACHE_TTL = 5 * 60 * 1000 // 5 minutes TTL\n\n  constructor() {\n    // Ensure in-memory storage is shared across module instances when Supabase is unavailable\n    const globalContext = globalThis as unknown as {\n      __fbcContextStore__?: {\n        data: Map<string, DatabaseConversationContext>\n        timestamps: Map<string, number>\n      }\n    }\n\n    if (!globalContext.__fbcContextStore__) {\n      globalContext.__fbcContextStore__ = {\n        data: new Map<string, DatabaseConversationContext>(),\n        timestamps: new Map<string, number>()\n      }\n    }\n\n    this.inMemoryStorage = globalContext.__fbcContextStore__.data\n    this.cacheTimestamps = globalContext.__fbcContextStore__.timestamps\n\n    // Try to create Supabase client, fallback to in-memory if unavailable\n    try {\n      if (process.env.NEXT_PUBLIC_SUPABASE_URL && process.env.SUPABASE_SERVICE_ROLE_KEY) {\n        this.supabase = getSupabaseService()\n      } else {\n        logger.warn('Supabase credentials not found, falling back to in-memory storage')\n        this.supabase = null\n      }\n    } catch (error) {\n      logger.warn('Supabase initialization failed, falling back to in-memory storage:', error)\n      this.supabase = null\n    }\n  }\n\n  async store(sessionId: string, payload: Partial<DatabaseConversationContext>): Promise<void> {\n    try {\n      // Convert to Insert type - only include fields that exist in the database schema\n      const dataToStore: ConversationContextInsert = {\n        session_id: sessionId,\n        email: payload.email || 'unknown@example.com', // Required field\n        name: payload.name ?? null,\n        company_context: payload.company_context ? toJson(payload.company_context) : null,\n        person_context: payload.person_context ? toJson(payload.person_context) : null,\n        role: payload.role ?? null,\n        role_confidence: payload.role_confidence ?? null,\n        intent_data: payload.intent_data ? toJson(payload.intent_data) : null,\n        ai_capabilities_shown: payload.ai_capabilities_shown ?? null,\n        last_user_message: payload.last_user_message ?? null,\n        company_url: payload.company_url ?? null,\n        updated_at: new Date().toISOString()\n      }\n\n      // Try Supabase first, fallback to in-memory\n      if (this.supabase) {\n        try {\n          const { error } = await this.supabase\n            .from('conversation_contexts')\n            .upsert(dataToStore)\n\n          if (error) {\n            throw error\n          }\n        } catch (supabaseError) {\n          logger.warn('Supabase storage failed, falling back to in-memory:', supabaseError)\n          // Store in memory with full DatabaseConversationContext structure\n          const inMemoryData: DatabaseConversationContext = {\n            session_id: sessionId,\n            email: payload.email || 'unknown@example.com',\n            ...payload,\n            updated_at: new Date().toISOString()\n          } as DatabaseConversationContext\n          this.inMemoryStorage.set(sessionId, inMemoryData)\n        }\n      } else {\n        // Use in-memory storage with full DatabaseConversationContext structure\n        const inMemoryData: DatabaseConversationContext = {\n          session_id: sessionId,\n          email: payload.email || 'unknown@example.com',\n          ...payload,\n          updated_at: new Date().toISOString()\n        } as DatabaseConversationContext\n        this.inMemoryStorage.set(sessionId, inMemoryData)\n      }\n    } catch (error) {\n      logger.error('Context storage failed completely:', error)\n      throw error\n    }\n  }\n\n  // Check if cached data is still valid (not expired)\n  private isCacheValid(sessionId: string): boolean {\n    const timestamp = this.cacheTimestamps.get(sessionId)\n    if (!timestamp) return false\n    return (Date.now() - timestamp) < this.CACHE_TTL\n  }\n\n  async get(sessionId: string): Promise<DatabaseConversationContext | null> {\n    try {\n      // Check if we have valid cached data first\n      const cachedData = this.inMemoryStorage.get(sessionId)\n      if (cachedData && this.isCacheValid(sessionId)) {\n        return cachedData\n      }\n\n      // Try Supabase first, fallback to in-memory\n      if (this.supabase) {\n        try {\n          const { data, error } = await this.supabase\n            .from('conversation_contexts')\n            .select('*')\n            .eq('session_id', sessionId)\n            .single()\n\n          if (error && error.code !== 'PGRST116') { // PGRST116 = no rows returned\n            throw error\n          }\n\n          // Parse and validate Supabase result\n          const rows = asContexts(data ? [data] : [])\n          const context = rows[0] ?? null\n\n          // Parse multimodal context if it exists as string\n          if (context && typeof context.multimodal_context === 'string') {\n            try {\n              const parsed: unknown = JSON.parse(context.multimodal_context)\n              context.multimodal_context = parsed as DatabaseConversationContext['multimodal_context']\n            } catch {\n              context.multimodal_context = undefined\n            }\n          }\n\n          // If we got data from Supabase, cache it with timestamp\n          if (context) {\n            this.inMemoryStorage.set(sessionId, context as DatabaseConversationContext)\n            this.cacheTimestamps.set(sessionId, Date.now())\n          }\n\n          return context as DatabaseConversationContext | null\n        } catch (supabaseError) {\n          logger.warn('Supabase retrieval failed, trying in-memory fallback:', supabaseError)\n          return this.inMemoryStorage.get(sessionId) || null\n        }\n      } else {\n        // Use in-memory storage only\n        return this.inMemoryStorage.get(sessionId) || null\n      }\n    } catch (error) {\n      logger.error('Context retrieval failed completely:', error)\n      return this.inMemoryStorage.get(sessionId) || null\n    }\n  }\n\n  // Clean up expired cache entries to prevent memory leaks\n  private cleanupExpiredCache(): void {\n    const now = Date.now()\n    const expiredKeys: string[] = []\n\n    for (const [sessionId, timestamp] of this.cacheTimestamps) {\n      if ((now - timestamp) > this.CACHE_TTL) {\n        expiredKeys.push(sessionId)\n      }\n    }\n\n    expiredKeys.forEach(sessionId => {\n      this.inMemoryStorage.delete(sessionId)\n      this.cacheTimestamps.delete(sessionId)\n    })\n\n    if (expiredKeys.length > 0) {\n      logger.debug(`Cleaned up ${expiredKeys.length} expired cache entries`)\n    }\n  }\n\n  async update(sessionId: string, patch: Partial<DatabaseConversationContext>): Promise<void> {\n    try {\n      // Try Supabase first, fallback to in-memory\n      if (this.supabase) {\n        try {\n          // Whitelist of valid conversation_contexts columns to prevent SQL errors\n          // Filter out any fields that don't exist in the table schema (e.g., 'capability' from capability_usage_log)\n          const validColumns = new Set([\n            'ai_capabilities_shown', 'analytics_pending', 'company_context', 'company_country',\n            'company_url', 'conversation_flow', 'created_at', 'email', 'event_id',\n            'intelligence_context', 'intent_data', 'last_agent', 'last_stage',\n            'last_user_message', 'metadata', 'name', 'pdf_generated_at', 'pdf_url',\n            'person_context', 'role', 'role_confidence', 'session_id', 'updated_at', 'version'\n          ])\n\n          // Filter patch to only include valid columns\n          const filteredPatch: Record<string, unknown> = {}\n          for (const [key, value] of Object.entries(patch)) {\n            if (validColumns.has(key)) {\n              filteredPatch[key] = value\n            }\n          }\n\n          // Convert metadata to Json type if present\n          const updateData: Record<string, unknown> = {\n            ...filteredPatch,\n            updated_at: new Date().toISOString()\n          }\n          if ('metadata' in updateData && updateData.metadata !== undefined && updateData.metadata !== null) {\n            updateData.metadata = toJson(updateData.metadata) as Json\n          }\n\n          const { error } = await this.supabase\n            .from('conversation_contexts')\n            .update(updateData)\n            .eq('session_id', sessionId)\n\n          if (error) {\n            throw error\n          }\n\n          // Also update in-memory cache if it exists\n          const existing = this.inMemoryStorage.get(sessionId)\n          if (existing) {\n            this.inMemoryStorage.set(sessionId, { ...existing, ...patch, updated_at: new Date().toISOString() } as DatabaseConversationContext)\n            this.cacheTimestamps.set(sessionId, Date.now()) // Refresh cache timestamp\n          }\n\n          // Periodic cleanup of expired entries\n          this.cleanupExpiredCache()\n        } catch (supabaseError) {\n          logger.warn('Supabase update failed, falling back to in-memory:', supabaseError)\n          // Update in-memory storage\n          const existing = this.inMemoryStorage.get(sessionId)\n          if (existing) {\n            this.inMemoryStorage.set(sessionId, { ...existing, ...patch, updated_at: new Date().toISOString() } as DatabaseConversationContext)\n            this.cacheTimestamps.set(sessionId, Date.now()) // Refresh cache timestamp\n          } else {\n            // Create new entry if it doesn't exist\n            this.inMemoryStorage.set(sessionId, {\n              session_id: sessionId,\n              email: 'unknown@example.com', // Required field\n              ...patch,\n              updated_at: new Date().toISOString()\n            } as DatabaseConversationContext)\n            this.cacheTimestamps.set(sessionId, Date.now()) // Set cache timestamp\n          }\n\n          // Periodic cleanup of expired entries\n          this.cleanupExpiredCache()\n        }\n      } else {\n        // Use in-memory storage only\n        const existing = this.inMemoryStorage.get(sessionId)\n        if (existing) {\n          this.inMemoryStorage.set(sessionId, { ...existing, ...patch, updated_at: new Date().toISOString() } as DatabaseConversationContext)\n          this.cacheTimestamps.set(sessionId, Date.now()) // Refresh cache timestamp\n        } else {\n          // Create new entry if it doesn't exist\n          this.inMemoryStorage.set(sessionId, {\n            session_id: sessionId,\n            email: 'unknown@example.com', // Required field\n            ...patch,\n            updated_at: new Date().toISOString()\n          } as DatabaseConversationContext)\n          this.cacheTimestamps.set(sessionId, Date.now()) // Set cache timestamp\n        }\n\n        // Periodic cleanup of expired entries\n        this.cleanupExpiredCache()\n      }\n    } catch (error) {\n      logger.error('Context update failed completely:', error)\n      throw error\n    }\n  }\n\n  async delete(sessionId: string): Promise<void> {\n    try {\n      // Try Supabase first, then in-memory\n      if (this.supabase) {\n        try {\n          const { error } = await this.supabase\n            .from('conversation_contexts')\n            .delete()\n            .eq('session_id', sessionId)\n\n          if (error) {\n            throw error\n          }\n        } catch (supabaseError) {\n          logger.warn('Supabase delete failed:', supabaseError)\n        }\n      }\n\n      // Always delete from in-memory storage\n      this.inMemoryStorage.delete(sessionId)\n    } catch (error) {\n      logger.error('Context deletion failed:', error)\n      throw error\n    }\n  }\n\n  /**\n   * Update with optimistic locking to prevent race conditions\n   * Uses version field to detect concurrent writes\n   */\n  async updateWithVersionCheck(\n    sessionId: string,\n    payload: Partial<DatabaseConversationContext>,\n    options: { attempts: number; backoff: number; signal?: AbortSignal }\n  ): Promise<void> {\n    let attempt = 0\n\n    while (attempt < options.attempts) {\n      if (options.signal?.aborted) {\n        throw new Error('AbortError')\n      }\n\n      try {\n        // Get current version\n        const current = await this.get(sessionId)\n\n        const metadataJson = resolveJsonField(payload.metadata, current?.metadata)\n        const conversationFlowJson = resolveJsonField(payload.conversation_flow, current?.conversation_flow)\n        const intelligenceContextJson = resolveJsonField(payload.intelligence_context, current?.intelligence_context)\n\n        // Convert to Insert type\n        const dataToStore: ConversationContextInsert = {\n          session_id: sessionId,\n          email: payload.email || current?.email || 'unknown@example.com',\n          name: payload.name ?? current?.name ?? null,\n          company_context: payload.company_context ? toJson(payload.company_context) : (current?.company_context ? toJson(current.company_context) : null),\n          person_context: payload.person_context ? toJson(payload.person_context) : (current?.person_context ? toJson(current.person_context) : null),\n          role: payload.role ?? current?.role ?? null,\n          role_confidence: payload.role_confidence ?? current?.role_confidence ?? null,\n          intent_data: payload.intent_data ? toJson(payload.intent_data) : (current?.intent_data ? toJson(current.intent_data) : null),\n          ai_capabilities_shown: payload.ai_capabilities_shown ?? current?.ai_capabilities_shown ?? null,\n          last_user_message: payload.last_user_message ?? current?.last_user_message ?? null,\n          company_url: payload.company_url ?? current?.company_url ?? null,\n          updated_at: new Date().toISOString()\n        }\n\n        if (metadataJson !== undefined) {\n          dataToStore.metadata = metadataJson\n        }\n        if (conversationFlowJson !== undefined) {\n          dataToStore.conversation_flow = conversationFlowJson\n        }\n        if (intelligenceContextJson !== undefined) {\n          dataToStore.intelligence_context = intelligenceContextJson\n        }\n        dataToStore.last_agent = payload.last_agent ?? current?.last_agent ?? null\n        dataToStore.last_stage = payload.last_stage ?? current?.last_stage ?? null\n        dataToStore.event_id = payload.event_id ?? current?.event_id ?? null\n        dataToStore.analytics_pending = payload.analytics_pending ?? current?.analytics_pending ?? null\n        dataToStore.version = payload.version ?? current?.version ?? null\n        dataToStore.pdf_url = payload.pdf_url ?? current?.pdf_url ?? null\n        dataToStore.pdf_generated_at = payload.pdf_generated_at ?? current?.pdf_generated_at ?? null\n\n        if (this.supabase) {\n          // If no record exists, insert instead of update\n          if (!current) {\n            const { data, error } = await this.supabase\n              .from('conversation_contexts')\n              .insert(dataToStore)\n              .select()\n              .single()\n\n            if (error) {\n              throw error\n            }\n\n            const rows = asContexts(data ? [data] : [])\n            const context = rows[0] ?? null\n            if (context) {\n              this.inMemoryStorage.set(sessionId, context as DatabaseConversationContext)\n              this.cacheTimestamps.set(sessionId, Date.now())\n              return\n            }\n          } else {\n            // Update existing record\n            const updateData: ConversationContextUpdate = {\n              name: payload.name ?? current?.name ?? null,\n              company_context: payload.company_context ? toJson(payload.company_context) : (current?.company_context ? toJson(current.company_context) : null),\n              person_context: payload.person_context ? toJson(payload.person_context) : (current?.person_context ? toJson(current.person_context) : null),\n              role: payload.role ?? current?.role ?? null,\n              role_confidence: payload.role_confidence ?? current?.role_confidence ?? null,\n              intent_data: payload.intent_data ? toJson(payload.intent_data) : (current?.intent_data ? toJson(current.intent_data) : null),\n              ai_capabilities_shown: payload.ai_capabilities_shown ?? current?.ai_capabilities_shown ?? null,\n              last_user_message: payload.last_user_message ?? current?.last_user_message ?? null,\n              company_url: payload.company_url ?? current?.company_url ?? null,\n              updated_at: new Date().toISOString()\n            }\n            if (metadataJson !== undefined) {\n              updateData.metadata = metadataJson\n            }\n            if (conversationFlowJson !== undefined) {\n              updateData.conversation_flow = conversationFlowJson\n            }\n            if (intelligenceContextJson !== undefined) {\n              updateData.intelligence_context = intelligenceContextJson\n            }\n            updateData.last_agent = payload.last_agent ?? current?.last_agent ?? null\n            updateData.last_stage = payload.last_stage ?? current?.last_stage ?? null\n            updateData.event_id = payload.event_id ?? current?.event_id ?? null\n            updateData.analytics_pending = payload.analytics_pending ?? current?.analytics_pending ?? null\n            updateData.version = payload.version ?? current?.version ?? null\n            updateData.pdf_url = payload.pdf_url ?? current?.pdf_url ?? null\n            updateData.pdf_generated_at = payload.pdf_generated_at ?? current?.pdf_generated_at ?? null\n            const { data, error } = await this.supabase\n              .from('conversation_contexts')\n              .update(updateData)\n              .eq('session_id', sessionId)\n              .select()\n\n            if (error) {\n              throw error\n            }\n\n            const rows = asContexts(data ?? [])\n            if (rows.length === 0) {\n              // Version mismatch - retry\n              throw new Error('VersionConflict')\n            }\n\n            // Update in-memory cache\n            this.inMemoryStorage.set(sessionId, rows[0] as DatabaseConversationContext)\n            this.cacheTimestamps.set(sessionId, Date.now())\n\n            return // Success\n          }\n        } else {\n          // Fallback to in-memory (no version check in memory)\n          const existing = this.inMemoryStorage.get(sessionId)\n          this.inMemoryStorage.set(sessionId, {\n            ...existing,\n            ...dataToStore\n          } as DatabaseConversationContext)\n          this.cacheTimestamps.set(sessionId, Date.now())\n          return\n        }\n      } catch (error) {\n        if (error instanceof Error && error.message === 'VersionConflict' && attempt < options.attempts - 1) {\n          const delay = calculateBackoffDelay(attempt + 1, {\n            baseDelay: options.backoff,\n            maxDelay: Number.POSITIVE_INFINITY,\n            backoffMultiplier: DEFAULT_BACKOFF_MULTIPLIER\n          })\n          await new Promise(resolve => setTimeout(resolve, delay))\n          attempt++\n          continue\n        }\n        throw error\n      }\n    }\n\n    throw new Error('Max version check attempts exceeded')\n  }\n}\n\n// Export singleton instance for backward compatibility\nexport const contextStorage = new ContextStorage()\n",
    "content2": "import { getSupabaseService } from '../../lib/supabase.js'\nimport { DatabaseConversationContext } from './context-types.js'\nimport { asContexts } from '../../lib/supabase-parsers.js'\nimport type { Database, Json } from '../database.types.js'\nimport { toJson } from '../types/json-guards.js'\nimport { calculateBackoffDelay, DEFAULT_BACKOFF_MULTIPLIER } from '../../lib/ai/retry-config.js'\n\ntype ConversationContextExtendedFields = {\n  metadata?: Json | null\n  conversation_flow?: Json | null\n  intelligence_context?: Json | null\n  last_agent?: string | null\n  last_stage?: string | null\n  event_id?: string | null\n  analytics_pending?: boolean | null\n  version?: number | null\n  pdf_url?: string | null\n  pdf_generated_at?: string | null\n}\n\ntype ConversationContextInsert = Database['public']['Tables']['conversation_contexts']['Insert'] & ConversationContextExtendedFields\ntype ConversationContextUpdate = Database['public']['Tables']['conversation_contexts']['Update'] & ConversationContextExtendedFields\n\nconst resolveJsonField = (\n  incoming: unknown | null | undefined,\n  existing: unknown | null | undefined\n): Json | null | undefined => {\n  if (incoming !== undefined) {\n    if (incoming === null) return null\n    try {\n      return toJson(incoming)\n    } catch {\n      // If toJson fails (e.g., value is undefined or invalid), return undefined to skip the field\n      return undefined\n    }\n  }\n  if (existing !== undefined) {\n    if (existing === null) return null\n    try {\n      return toJson(existing)\n    } catch {\n      // If toJson fails (e.g., value is undefined or invalid), return undefined to skip the field\n      return undefined\n    }\n  }\n  return undefined\n}\n\n// Browser-safe logger (winston is Node.js only)\nconst logger = {\n  warn: console.warn.bind(console),\n  error: console.error.bind(console),\n  debug: console.debug.bind(console),\n  info: console.info.bind(console),\n}\n\nexport class ContextStorage {\n  // Use the service client type to avoid Database generic issues.\n  private supabase: ReturnType<typeof getSupabaseService> | null\n  private inMemoryStorage: Map<string, DatabaseConversationContext>\n  private cacheTimestamps: Map<string, number>\n  private readonly CACHE_TTL = 5 * 60 * 1000 // 5 minutes TTL\n\n  constructor() {\n    // Ensure in-memory storage is shared across module instances when Supabase is unavailable\n    const globalContext = globalThis as unknown as {\n      __fbcContextStore__?: {\n        data: Map<string, DatabaseConversationContext>\n        timestamps: Map<string, number>\n      }\n    }\n\n    if (!globalContext.__fbcContextStore__) {\n      globalContext.__fbcContextStore__ = {\n        data: new Map<string, DatabaseConversationContext>(),\n        timestamps: new Map<string, number>()\n      }\n    }\n\n    this.inMemoryStorage = globalContext.__fbcContextStore__.data\n    this.cacheTimestamps = globalContext.__fbcContextStore__.timestamps\n\n    // Try to create Supabase client, fallback to in-memory if unavailable\n    try {\n      if (process.env.NEXT_PUBLIC_SUPABASE_URL && process.env.SUPABASE_SERVICE_ROLE_KEY) {\n        this.supabase = getSupabaseService()\n      } else {\n        logger.warn('Supabase credentials not found, falling back to in-memory storage')\n        this.supabase = null\n      }\n    } catch (error) {\n      logger.warn('Supabase initialization failed, falling back to in-memory storage:', error)\n      this.supabase = null\n    }\n  }\n\n  async store(sessionId: string, payload: Partial<DatabaseConversationContext>): Promise<void> {\n    try {\n      // Convert to Insert type - only include fields that exist in the database schema\n      const dataToStore: ConversationContextInsert = {\n        session_id: sessionId,\n        email: payload.email || 'unknown@example.com', // Required field\n        name: payload.name ?? null,\n        company_context: payload.company_context ? toJson(payload.company_context) : null,\n        person_context: payload.person_context ? toJson(payload.person_context) : null,\n        role: payload.role ?? null,\n        role_confidence: payload.role_confidence ?? null,\n        intent_data: payload.intent_data ? toJson(payload.intent_data) : null,\n        ai_capabilities_shown: payload.ai_capabilities_shown ?? null,\n        last_user_message: payload.last_user_message ?? null,\n        company_url: payload.company_url ?? null,\n        updated_at: new Date().toISOString()\n      }\n\n      // Try Supabase first, fallback to in-memory\n      if (this.supabase) {\n        try {\n          const { error } = await this.supabase\n            .from('conversation_contexts')\n            .upsert(dataToStore)\n\n          if (error) {\n            throw error\n          }\n        } catch (supabaseError) {\n          logger.warn('Supabase storage failed, falling back to in-memory:', supabaseError)\n          // Store in memory with full DatabaseConversationContext structure\n          const inMemoryData: DatabaseConversationContext = {\n            session_id: sessionId,\n            email: payload.email || 'unknown@example.com',\n            ...payload,\n            updated_at: new Date().toISOString()\n          } as DatabaseConversationContext\n          this.inMemoryStorage.set(sessionId, inMemoryData)\n        }\n      } else {\n        // Use in-memory storage with full DatabaseConversationContext structure\n        const inMemoryData: DatabaseConversationContext = {\n          session_id: sessionId,\n          email: payload.email || 'unknown@example.com',\n          ...payload,\n          updated_at: new Date().toISOString()\n        } as DatabaseConversationContext\n        this.inMemoryStorage.set(sessionId, inMemoryData)\n      }\n    } catch (error) {\n      logger.error('Context storage failed completely:', error)\n      throw error\n    }\n  }\n\n  // Check if cached data is still valid (not expired)\n  private isCacheValid(sessionId: string): boolean {\n    const timestamp = this.cacheTimestamps.get(sessionId)\n    if (!timestamp) return false\n    return (Date.now() - timestamp) < this.CACHE_TTL\n  }\n\n  async get(sessionId: string): Promise<DatabaseConversationContext | null> {\n    try {\n      // Check if we have valid cached data first\n      const cachedData = this.inMemoryStorage.get(sessionId)\n      if (cachedData && this.isCacheValid(sessionId)) {\n        return cachedData\n      }\n\n      // Try Supabase first, fallback to in-memory\n      if (this.supabase) {\n        try {\n          const { data, error } = await this.supabase\n            .from('conversation_contexts')\n            .select('*')\n            .eq('session_id', sessionId)\n            .single()\n\n          if (error && error.code !== 'PGRST116') { // PGRST116 = no rows returned\n            throw error\n          }\n\n          // Parse and validate Supabase result\n          const rows = asContexts(data ? [data] : [])\n          const context = rows[0] ?? null\n          \n          // Parse multimodal context if it exists as string\n          if (context && typeof context.multimodal_context === 'string') {\n            try {\n              const parsed: unknown = JSON.parse(context.multimodal_context)\n              context.multimodal_context = parsed as DatabaseConversationContext['multimodal_context']\n            } catch {\n              context.multimodal_context = undefined\n            }\n          }\n\n          // If we got data from Supabase, cache it with timestamp\n          if (context) {\n            this.inMemoryStorage.set(sessionId, context as DatabaseConversationContext)\n            this.cacheTimestamps.set(sessionId, Date.now())\n          }\n\n          return context as DatabaseConversationContext | null\n        } catch (supabaseError) {\n          logger.warn('Supabase retrieval failed, trying in-memory fallback:', supabaseError)\n          return this.inMemoryStorage.get(sessionId) || null\n        }\n      } else {\n        // Use in-memory storage only\n        return this.inMemoryStorage.get(sessionId) || null\n      }\n    } catch (error) {\n      logger.error('Context retrieval failed completely:', error)\n      return this.inMemoryStorage.get(sessionId) || null\n    }\n  }\n\n  // Clean up expired cache entries to prevent memory leaks\n  private cleanupExpiredCache(): void {\n    const now = Date.now()\n    const expiredKeys: string[] = []\n\n    for (const [sessionId, timestamp] of this.cacheTimestamps) {\n      if ((now - timestamp) > this.CACHE_TTL) {\n        expiredKeys.push(sessionId)\n      }\n    }\n\n    expiredKeys.forEach(sessionId => {\n      this.inMemoryStorage.delete(sessionId)\n      this.cacheTimestamps.delete(sessionId)\n    })\n\n    if (expiredKeys.length > 0) {\n      logger.debug(`Cleaned up ${expiredKeys.length} expired cache entries`)\n    }\n  }\n\n  async update(sessionId: string, patch: Partial<DatabaseConversationContext>): Promise<void> {\n    try {\n      // Try Supabase first, fallback to in-memory\n      if (this.supabase) {\n        try {\n          // Whitelist of valid conversation_contexts columns to prevent SQL errors\n          // Filter out any fields that don't exist in the table schema (e.g., 'capability' from capability_usage_log)\n          const validColumns = new Set([\n            'ai_capabilities_shown', 'analytics_pending', 'company_context', 'company_country',\n            'company_url', 'conversation_flow', 'created_at', 'email', 'event_id',\n            'intelligence_context', 'intent_data', 'last_agent', 'last_stage',\n            'last_user_message', 'metadata', 'name', 'pdf_generated_at', 'pdf_url',\n            'person_context', 'role', 'role_confidence', 'session_id', 'updated_at', 'version'\n          ])\n          \n          // Filter patch to only include valid columns\n          const filteredPatch: Record<string, unknown> = {}\n          for (const [key, value] of Object.entries(patch)) {\n            if (validColumns.has(key)) {\n              filteredPatch[key] = value\n            }\n          }\n          \n          // Convert metadata to Json type if present\n          const updateData: Record<string, unknown> = {\n            ...filteredPatch,\n            updated_at: new Date().toISOString()\n          }\n          if ('metadata' in updateData && updateData.metadata !== undefined && updateData.metadata !== null) {\n            updateData.metadata = toJson(updateData.metadata) as Json\n          }\n          \n          const { error } = await this.supabase\n            .from('conversation_contexts')\n            .update(updateData)\n            .eq('session_id', sessionId)\n\n          if (error) {\n            throw error\n          }\n\n          // Also update in-memory cache if it exists\n          const existing = this.inMemoryStorage.get(sessionId)\n          if (existing) {\n            this.inMemoryStorage.set(sessionId, { ...existing, ...patch, updated_at: new Date().toISOString() } as DatabaseConversationContext)\n            this.cacheTimestamps.set(sessionId, Date.now()) // Refresh cache timestamp\n          }\n\n          // Periodic cleanup of expired entries\n          this.cleanupExpiredCache()\n        } catch (supabaseError) {\n          logger.warn('Supabase update failed, falling back to in-memory:', supabaseError)\n          // Update in-memory storage\n          const existing = this.inMemoryStorage.get(sessionId)\n          if (existing) {\n            this.inMemoryStorage.set(sessionId, { ...existing, ...patch, updated_at: new Date().toISOString() } as DatabaseConversationContext)\n            this.cacheTimestamps.set(sessionId, Date.now()) // Refresh cache timestamp\n          } else {\n            // Create new entry if it doesn't exist\n            this.inMemoryStorage.set(sessionId, {\n              session_id: sessionId,\n              email: 'unknown@example.com', // Required field\n              ...patch,\n              updated_at: new Date().toISOString()\n            } as DatabaseConversationContext)\n            this.cacheTimestamps.set(sessionId, Date.now()) // Set cache timestamp\n          }\n\n          // Periodic cleanup of expired entries\n          this.cleanupExpiredCache()\n        }\n      } else {\n        // Use in-memory storage only\n        const existing = this.inMemoryStorage.get(sessionId)\n        if (existing) {\n          this.inMemoryStorage.set(sessionId, { ...existing, ...patch, updated_at: new Date().toISOString() } as DatabaseConversationContext)\n          this.cacheTimestamps.set(sessionId, Date.now()) // Refresh cache timestamp\n        } else {\n          // Create new entry if it doesn't exist\n          this.inMemoryStorage.set(sessionId, {\n            session_id: sessionId,\n            email: 'unknown@example.com', // Required field\n            ...patch,\n            updated_at: new Date().toISOString()\n          } as DatabaseConversationContext)\n          this.cacheTimestamps.set(sessionId, Date.now()) // Set cache timestamp\n        }\n\n        // Periodic cleanup of expired entries\n        this.cleanupExpiredCache()\n      }\n    } catch (error) {\n      logger.error('Context update failed completely:', error)\n      throw error\n    }\n  }\n\n  async delete(sessionId: string): Promise<void> {\n    try {\n      // Try Supabase first, then in-memory\n      if (this.supabase) {\n        try {\n          const { error } = await this.supabase\n            .from('conversation_contexts')\n            .delete()\n            .eq('session_id', sessionId)\n\n          if (error) {\n            throw error\n          }\n        } catch (supabaseError) {\n          logger.warn('Supabase delete failed:', supabaseError)\n        }\n      }\n\n      // Always delete from in-memory storage\n      this.inMemoryStorage.delete(sessionId)\n    } catch (error) {\n      logger.error('Context deletion failed:', error)\n      throw error\n    }\n  }\n\n  /**\n   * Update with optimistic locking to prevent race conditions\n   * Uses version field to detect concurrent writes\n   */\n  async updateWithVersionCheck(\n    sessionId: string,\n    payload: Partial<DatabaseConversationContext>,\n    options: { attempts: number; backoff: number; signal?: AbortSignal }\n  ): Promise<void> {\n    let attempt = 0\n    \n    while (attempt < options.attempts) {\n      if (options.signal?.aborted) {\n        throw new Error('AbortError')\n      }\n      \n      try {\n        // Get current version\n        const current = await this.get(sessionId)\n        \n        const metadataJson = resolveJsonField(payload.metadata, current?.metadata)\n        const conversationFlowJson = resolveJsonField(payload.conversation_flow, current?.conversation_flow)\n        const intelligenceContextJson = resolveJsonField(payload.intelligence_context, current?.intelligence_context)\n        \n        // Convert to Insert type\n        const dataToStore: ConversationContextInsert = {\n          session_id: sessionId,\n          email: payload.email || current?.email || 'unknown@example.com',\n          name: payload.name ?? current?.name ?? null,\n          company_context: payload.company_context ? toJson(payload.company_context) : (current?.company_context ? toJson(current.company_context) : null),\n          person_context: payload.person_context ? toJson(payload.person_context) : (current?.person_context ? toJson(current.person_context) : null),\n          role: payload.role ?? current?.role ?? null,\n          role_confidence: payload.role_confidence ?? current?.role_confidence ?? null,\n          intent_data: payload.intent_data ? toJson(payload.intent_data) : (current?.intent_data ? toJson(current.intent_data) : null),\n          ai_capabilities_shown: payload.ai_capabilities_shown ?? current?.ai_capabilities_shown ?? null,\n          last_user_message: payload.last_user_message ?? current?.last_user_message ?? null,\n          company_url: payload.company_url ?? current?.company_url ?? null,\n          updated_at: new Date().toISOString()\n        }\n        \n        if (metadataJson !== undefined) {\n          dataToStore.metadata = metadataJson\n        }\n        if (conversationFlowJson !== undefined) {\n          dataToStore.conversation_flow = conversationFlowJson\n        }\n        if (intelligenceContextJson !== undefined) {\n          dataToStore.intelligence_context = intelligenceContextJson\n        }\n        dataToStore.last_agent = payload.last_agent ?? current?.last_agent ?? null\n        dataToStore.last_stage = payload.last_stage ?? current?.last_stage ?? null\n        dataToStore.event_id = payload.event_id ?? current?.event_id ?? null\n        dataToStore.analytics_pending = payload.analytics_pending ?? current?.analytics_pending ?? null\n        dataToStore.version = payload.version ?? current?.version ?? null\n        dataToStore.pdf_url = payload.pdf_url ?? current?.pdf_url ?? null\n        dataToStore.pdf_generated_at = payload.pdf_generated_at ?? current?.pdf_generated_at ?? null\n        \n        if (this.supabase) {\n          // If no record exists, insert instead of update\n          if (!current) {\n            const { data, error } = await this.supabase\n              .from('conversation_contexts')\n              .insert(dataToStore)\n              .select()\n              .single()\n            \n            if (error) {\n              throw error\n            }\n            \n            const rows = asContexts(data ? [data] : [])\n            const context = rows[0] ?? null\n            if (context) {\n              this.inMemoryStorage.set(sessionId, context as DatabaseConversationContext)\n              this.cacheTimestamps.set(sessionId, Date.now())\n              return\n            }\n          } else {\n            // Update existing record\n            const updateData: ConversationContextUpdate = {\n              name: payload.name ?? current?.name ?? null,\n              company_context: payload.company_context ? toJson(payload.company_context) : (current?.company_context ? toJson(current.company_context) : null),\n              person_context: payload.person_context ? toJson(payload.person_context) : (current?.person_context ? toJson(current.person_context) : null),\n              role: payload.role ?? current?.role ?? null,\n              role_confidence: payload.role_confidence ?? current?.role_confidence ?? null,\n              intent_data: payload.intent_data ? toJson(payload.intent_data) : (current?.intent_data ? toJson(current.intent_data) : null),\n              ai_capabilities_shown: payload.ai_capabilities_shown ?? current?.ai_capabilities_shown ?? null,\n              last_user_message: payload.last_user_message ?? current?.last_user_message ?? null,\n              company_url: payload.company_url ?? current?.company_url ?? null,\n              updated_at: new Date().toISOString()\n            }\n            if (metadataJson !== undefined) {\n              updateData.metadata = metadataJson\n            }\n            if (conversationFlowJson !== undefined) {\n              updateData.conversation_flow = conversationFlowJson\n            }\n            if (intelligenceContextJson !== undefined) {\n              updateData.intelligence_context = intelligenceContextJson\n            }\n            updateData.last_agent = payload.last_agent ?? current?.last_agent ?? null\n            updateData.last_stage = payload.last_stage ?? current?.last_stage ?? null\n            updateData.event_id = payload.event_id ?? current?.event_id ?? null\n            updateData.analytics_pending = payload.analytics_pending ?? current?.analytics_pending ?? null\n            updateData.version = payload.version ?? current?.version ?? null\n            updateData.pdf_url = payload.pdf_url ?? current?.pdf_url ?? null\n            updateData.pdf_generated_at = payload.pdf_generated_at ?? current?.pdf_generated_at ?? null\n            const { data, error } = await this.supabase\n              .from('conversation_contexts')\n              .update(updateData)\n              .eq('session_id', sessionId)\n              .select()\n            \n            if (error) {\n              throw error\n            }\n            \n            const rows = asContexts(data ?? [])\n            if (rows.length === 0) {\n              // Version mismatch - retry\n              throw new Error('VersionConflict')\n            }\n            \n            // Update in-memory cache\n            this.inMemoryStorage.set(sessionId, rows[0] as DatabaseConversationContext)\n            this.cacheTimestamps.set(sessionId, Date.now())\n            \n            return // Success\n          }\n        } else {\n          // Fallback to in-memory (no version check in memory)\n          const existing = this.inMemoryStorage.get(sessionId)\n          this.inMemoryStorage.set(sessionId, {\n            ...existing,\n            ...dataToStore\n          } as DatabaseConversationContext)\n          this.cacheTimestamps.set(sessionId, Date.now())\n          return\n        }\n      } catch (error) {\n        if (error instanceof Error && error.message === 'VersionConflict' && attempt < options.attempts - 1) {\n          const delay = calculateBackoffDelay(attempt + 1, {\n            baseDelay: options.backoff,\n            maxDelay: Number.POSITIVE_INFINITY,\n            backoffMultiplier: DEFAULT_BACKOFF_MULTIPLIER\n          })\n          await new Promise(resolve => setTimeout(resolve, delay))\n          attempt++\n          continue\n        }\n        throw error\n      }\n    }\n    \n    throw new Error('Max version check attempts exceeded')\n  }\n}\n\n// Export singleton instance for backward compatibility\nexport const contextStorage = new ContextStorage()\n"
  },
  "analytics/agent-analytics": {
    "status": "different",
    "differences": [
      "Significant line count difference: 247 vs 205 lines"
    ],
    "stats": {
      "source": {
        "lines": 247,
        "exports": 6,
        "functions": 0,
        "classes": 1
      },
      "target": {
        "lines": 205,
        "exports": 6,
        "functions": 0,
        "classes": 1
      }
    },
    "content1": "import { getSupabaseService } from '../../lib/supabase.js'\nimport { asJsonObject } from '../../types/json-guards.js'\nimport type { Json } from '../../supabase/database.types.js'\n\ninterface AuditLogDetails {\n  agent?: string\n  stage?: string\n  performance?: {\n    success?: boolean\n    duration?: number\n  }\n}\n\nexport interface AgentAnalytics {\n  totalExecutions: number\n  successRate: number\n  averageDuration: number\n  agentBreakdown: Record<string, number>\n  stageBreakdown: Record<string, number>\n}\n\nexport interface StageConversion {\n  stage: string\n  count: number\n  conversionRate?: number\n  averageDuration: number\n}\n\nexport interface ToolAnalytics {\n  totalExecutions: number\n  successRate: number\n  averageDuration: number\n  cacheHitRate: number\n  toolBreakdown: Record<string, {\n    count: number\n    successRate: number\n    averageDuration: number\n  }>\n}\n\nexport interface SystemHealth {\n  errorRate: number\n  avgLatency: number\n  cacheHitRate: number\n  totalSessions: number\n}\n\nconst DEFAULT_AGENT_ANALYTICS: AgentAnalytics = {\n  totalExecutions: 0,\n  successRate: 0,\n  averageDuration: 0,\n  agentBreakdown: {},\n  stageBreakdown: {}\n}\n\nexport class AgentAnalyticsService {\n  async getAnalytics(\n    sessionId?: string,\n    timeRange?: { start: Date; end: Date }\n  ): Promise<AgentAnalytics> {\n    const supabase = getSupabaseService()\n    if (!supabase) {\n      console.warn('Supabase service unavailable - returning default agent analytics')\n      return DEFAULT_AGENT_ANALYTICS\n    }\n\n    let query = supabase\n      .from('audit_log')\n      .select('*')\n      .in('event', ['agent_routed', 'agent_execution'])\n\n    if (sessionId) {\n      query = query.eq('session_id', sessionId)\n    }\n\n    if (timeRange) {\n      query = query\n        .gte('timestamp', timeRange.start.toISOString())\n        .lte('timestamp', timeRange.end.toISOString())\n    }\n\n    const { data, error } = await query\n\n    if (error || !data) {\n      throw new Error(`Failed to fetch analytics: ${error?.message}`)\n    }\n\n    // Calculate metrics\n    const executions = data.filter((log: { event?: string }) => log.event === 'agent_execution')\n    const totalExecutions = executions.length\n\n    const successCount = executions.filter((log: { details?: unknown }) => {\n      const details = asJsonObject((log.details as any) as Json | undefined) as AuditLogDetails | undefined\n      return details?.performance?.success === true\n    }).length\n    const successRate = totalExecutions > 0 ? successCount / totalExecutions : 0\n\n    const durations = executions\n      .map((log: { details?: unknown }) => {\n        const details = asJsonObject((log.details as any) as Json | undefined) as AuditLogDetails | undefined\n        return details?.performance?.duration\n      })\n      .filter((d: unknown): d is number => typeof d === 'number')\n    const averageDuration = durations.length > 0\n      ? durations.reduce((a: number, b: number) => a + b, 0) / durations.length\n      : 0\n\n    const agentBreakdown: Record<string, number> = {}\n    const stageBreakdown: Record<string, number> = {}\n\n    data.forEach((log: { details?: unknown }) => {\n      const details = asJsonObject((log.details as any) as Json | undefined) as AuditLogDetails | undefined\n      const agent = details?.agent\n      const stage = details?.stage\n\n      if (agent) {\n        agentBreakdown[agent] = (agentBreakdown[agent] || 0) + 1\n      }\n      if (stage) {\n        stageBreakdown[stage] = (stageBreakdown[stage] || 0) + 1\n      }\n    })\n\n    return {\n      totalExecutions,\n      successRate,\n      averageDuration,\n      agentBreakdown,\n      stageBreakdown\n    }\n  }\n\n  /**\n   * Get stage conversion rates (funnel progression)\n   */\n  async getStageConversion(\n    timeRange?: { start: Date; end: Date }\n  ): Promise<StageConversion[]> {\n    const supabase = getSupabaseService()\n    if (!supabase) {\n      console.warn('Supabase service unavailable - skipping stage conversion analytics')\n      return []\n    }\n\n    let query = supabase\n      .from('audit_log')\n      .select('*')\n      .eq('event', 'agent_routed')\n\n    if (timeRange) {\n      query = query\n        .gte('timestamp', timeRange.start.toISOString())\n        .lte('timestamp', timeRange.end.toISOString())\n    }\n\n    const { data, error } = await query\n\n    if (error || !data) {\n      throw new Error(`Failed to fetch stage conversion: ${error?.message}`)\n    }\n\n    // Group by stage\n    const stageGroups: Record<string, { count: number; durations: number[] }> = {}\n\n    data.forEach((log: { details?: unknown }) => {\n      const details = asJsonObject((log.details as any) as Json | undefined) as AuditLogDetails | undefined\n      const stage = details?.stage\n      if (stage) {\n        if (!stageGroups[stage]) {\n          stageGroups[stage] = { count: 0, durations: [] }\n        }\n        stageGroups[stage].count++\n\n        // Get execution duration if available from related execution log\n        const duration = details?.performance?.duration\n        if (typeof duration === 'number') {\n          stageGroups[stage].durations.push(duration)\n        }\n      }\n    })\n\n    // Calculate conversion rates (assuming stages flow: DISCOVERY -> SCORING -> SALES -> CLOSING)\n    const stages = ['DISCOVERY', 'SCORING', 'WORKSHOP_PITCH', 'CONSULTING_PITCH', 'CLOSING', 'SUMMARY']\n    const stageCounts = stages.map(s => stageGroups[s]?.count || 0)\n    const total = stageCounts[0] || 1 // Use DISCOVERY as base\n\n    return stages.map((stage, index) => {\n      const stageData = stageGroups[stage] || { count: 0, durations: [] }\n      const count = stageData.count\n      const conversionRate = index === 0 ? 1 : count / total\n      const averageDuration = stageData.durations.length > 0\n        ? stageData.durations.reduce((a: number, b: number) => a + b, 0) / stageData.durations.length\n        : 0\n\n      return {\n        stage,\n        count,\n        conversionRate: index === 0 ? 1 : conversionRate,\n        averageDuration\n      }\n    }).filter(s => s.count > 0)\n  }\n\n  /**\n   * Log agent execution directly to Supabase (synchronous, no queue)\n   * This fixes the \"No handler registered for job type: agent-analytics\" error\n   */\n  async logExecution(data: {\n    sessionId: string\n    agent: string\n    stage: string\n    duration: number\n    success: boolean\n    multimodalUsed?: boolean\n    error?: string\n  }): Promise<void> {\n    const supabase = getSupabaseService()\n    if (!supabase) {\n      console.warn('Supabase service unavailable - skipping analytics logging')\n      return\n    }\n\n    try {\n      await supabase.from('audit_log').insert({\n        session_id: data.sessionId,\n        event: 'agent_execution',\n        details: {\n          agent: data.agent,\n          stage: data.stage,\n          performance: {\n            duration: data.duration,\n            success: data.success\n          },\n          multimodal_used: data.multimodalUsed,\n          error: data.error\n        },\n        timestamp: new Date().toISOString()\n      })\n    } catch (error) {\n      // Non-fatal - just log the error\n      console.warn('Failed to log agent execution analytics:', error)\n    }\n  }\n}\n\nexport const agentAnalytics = new AgentAnalyticsService()\n",
    "content2": "import { getSupabaseService } from '@/lib/supabase'\nimport { asJsonObject } from '../types/json-guards'\n\ninterface AuditLogDetails {\n  agent?: string\n  stage?: string\n  performance?: {\n    success?: boolean\n    duration?: number\n  }\n}\n\nexport interface AgentAnalytics {\n  totalExecutions: number\n  successRate: number\n  averageDuration: number\n  agentBreakdown: Record<string, number>\n  stageBreakdown: Record<string, number>\n}\n\nexport interface StageConversion {\n  stage: string\n  count: number\n  conversionRate?: number\n  averageDuration: number\n}\n\nexport interface ToolAnalytics {\n  totalExecutions: number\n  successRate: number\n  averageDuration: number\n  cacheHitRate: number\n  toolBreakdown: Record<string, {\n    count: number\n    successRate: number\n    averageDuration: number\n  }>\n}\n\nexport interface SystemHealth {\n  errorRate: number\n  avgLatency: number\n  cacheHitRate: number\n  totalSessions: number\n}\n\nconst DEFAULT_AGENT_ANALYTICS: AgentAnalytics = {\n  totalExecutions: 0,\n  successRate: 0,\n  averageDuration: 0,\n  agentBreakdown: {},\n  stageBreakdown: {}\n}\n\nexport class AgentAnalyticsService {\n  async getAnalytics(\n    sessionId?: string,\n    timeRange?: { start: Date; end: Date }\n  ): Promise<AgentAnalytics> {\n    const supabase = getSupabaseService()\n    if (!supabase) {\n      console.warn('Supabase service unavailable - returning default agent analytics')\n      return DEFAULT_AGENT_ANALYTICS\n    }\n    \n    let query = supabase\n      .from('audit_log')\n      .select('*')\n      .in('event', ['agent_routed', 'agent_execution'])\n    \n    if (sessionId) {\n      query = query.eq('session_id', sessionId)\n    }\n    \n    if (timeRange) {\n      query = query\n        .gte('timestamp', timeRange.start.toISOString())\n        .lte('timestamp', timeRange.end.toISOString())\n    }\n    \n    const { data, error } = await query\n    \n    if (error || !data) {\n      throw new Error(`Failed to fetch analytics: ${error?.message}`)\n    }\n    \n    // Calculate metrics\n    const executions = data.filter((log) => log.event === 'agent_execution')\n    const totalExecutions = executions.length\n    \n    const successCount = executions.filter((log) => {\n      const details = asJsonObject(log.details) as AuditLogDetails | undefined\n      return details?.performance?.success === true\n    }).length\n    const successRate = totalExecutions > 0 ? successCount / totalExecutions : 0\n    \n    const durations = executions\n      .map((log) => {\n        const details = asJsonObject(log.details) as AuditLogDetails | undefined\n        return details?.performance?.duration\n      })\n      .filter((d): d is number => typeof d === 'number')\n    const averageDuration = durations.length > 0 \n      ? durations.reduce((a: number, b: number) => a + b, 0) / durations.length \n      : 0\n    \n    const agentBreakdown: Record<string, number> = {}\n    const stageBreakdown: Record<string, number> = {}\n    \n    data.forEach((log) => {\n      const details = asJsonObject(log.details) as AuditLogDetails | undefined\n      const agent = details?.agent\n      const stage = details?.stage\n      \n      if (agent) {\n        agentBreakdown[agent] = (agentBreakdown[agent] || 0) + 1\n      }\n      if (stage) {\n        stageBreakdown[stage] = (stageBreakdown[stage] || 0) + 1\n      }\n    })\n    \n    return {\n      totalExecutions,\n      successRate,\n      averageDuration,\n      agentBreakdown,\n      stageBreakdown\n    }\n  }\n\n  /**\n   * Get stage conversion rates (funnel progression)\n   */\n  async getStageConversion(\n    timeRange?: { start: Date; end: Date }\n  ): Promise<StageConversion[]> {\n    const supabase = getSupabaseService()\n    if (!supabase) {\n      console.warn('Supabase service unavailable - skipping stage conversion analytics')\n      return []\n    }\n    \n    let query = supabase\n      .from('audit_log')\n      .select('*')\n      .eq('event', 'agent_routed')\n    \n    if (timeRange) {\n      query = query\n        .gte('timestamp', timeRange.start.toISOString())\n        .lte('timestamp', timeRange.end.toISOString())\n    }\n    \n    const { data, error } = await query\n    \n    if (error || !data) {\n      throw new Error(`Failed to fetch stage conversion: ${error?.message}`)\n    }\n    \n    // Group by stage\n    const stageGroups: Record<string, { count: number; durations: number[] }> = {}\n    \n    data.forEach((log) => {\n      const details = asJsonObject(log.details) as AuditLogDetails | undefined\n      const stage = details?.stage\n      if (stage) {\n        if (!stageGroups[stage]) {\n          stageGroups[stage] = { count: 0, durations: [] }\n        }\n        stageGroups[stage].count++\n        \n        // Get execution duration if available from related execution log\n        const duration = details?.performance?.duration\n        if (typeof duration === 'number') {\n          stageGroups[stage].durations.push(duration)\n        }\n      }\n    })\n    \n    // Calculate conversion rates (assuming stages flow: DISCOVERY -> SCORING -> SALES -> CLOSING)\n    const stages = ['DISCOVERY', 'SCORING', 'WORKSHOP_PITCH', 'CONSULTING_PITCH', 'CLOSING', 'SUMMARY']\n    const stageCounts = stages.map(s => stageGroups[s]?.count || 0)\n    const total = stageCounts[0] || 1 // Use DISCOVERY as base\n    \n    return stages.map((stage, index) => {\n      const stageData = stageGroups[stage] || { count: 0, durations: [] }\n      const count = stageData.count\n      const conversionRate = index === 0 ? 1 : count / total\n      const averageDuration = stageData.durations.length > 0\n        ? stageData.durations.reduce((a: number, b: number) => a + b, 0) / stageData.durations.length\n        : 0\n      \n      return {\n        stage,\n        count,\n        conversionRate: index === 0 ? 1 : conversionRate,\n        averageDuration\n      }\n    }).filter(s => s.count > 0)\n  }\n}\n\nexport const agentAnalytics = new AgentAnalyticsService()\n"
  },
  "analytics/tool-analytics": {
    "status": "identical",
    "differences": [],
    "stats": {
      "source": {
        "lines": 128,
        "exports": 2,
        "functions": 0,
        "classes": 1
      },
      "target": {
        "lines": 127,
        "exports": 2,
        "functions": 0,
        "classes": 1
      }
    },
    "content1": "import { getSupabaseService } from '../../utils/supabase.js'\nimport type { ToolAnalytics } from './agent-analytics.js'\nimport { asJsonObject } from '../../types/json-guards.js'\nimport type { Json } from '../../supabase/database.types.js'\n\nconst DEFAULT_TOOL_ANALYTICS: ToolAnalytics = {\n  totalExecutions: 0,\n  successRate: 0,\n  averageDuration: 0,\n  cacheHitRate: 0,\n  toolBreakdown: {}\n}\n\ninterface AuditLogDetails {\n  toolName?: string\n  cached?: boolean\n  performance?: {\n    success?: boolean\n    duration?: number\n  }\n}\n\nexport class ToolAnalyticsService {\n  async getToolAnalytics(\n    timeRange?: { start: Date; end: Date }\n  ): Promise<ToolAnalytics> {\n    const supabase = getSupabaseService()\n    if (!supabase) {\n      console.warn('Supabase service unavailable - returning default tool analytics')\n      return DEFAULT_TOOL_ANALYTICS\n    }\n    \n    let query = supabase\n      .from('audit_log')\n      .select('*')\n      .eq('event', 'tool_executed')\n    \n    if (timeRange) {\n      query = query\n        .gte('timestamp', timeRange.start.toISOString())\n        .lte('timestamp', timeRange.end.toISOString())\n    }\n    \n    const { data, error } = await query\n    \n    if (error || !data) {\n      throw new Error(`Failed to fetch tool analytics: ${error?.message}`)\n    }\n    \n    const totalExecutions = data.length\n    const successCount = data.filter((log: { details: Json | null | undefined }) => {\n      const details = asJsonObject(log.details) as AuditLogDetails | undefined\n      return details?.performance?.success === true\n    }).length\n    const successRate = totalExecutions > 0 ? successCount / totalExecutions : 0\n    \n    const durations = data\n      .map((log: { details: Json | null | undefined }) => {\n        const details = asJsonObject(log.details) as AuditLogDetails | undefined\n        return details?.performance?.duration\n      })\n      .filter((d: unknown): d is number => typeof d === 'number')\n    const averageDuration = durations.length > 0 \n      ? durations.reduce((a: number, b: number) => a + b, 0) / durations.length \n      : 0\n    \n    const cachedCount = data.filter((log: { details: Json | null | undefined }) => {\n      const details = asJsonObject(log.details) as AuditLogDetails | undefined\n      return details?.cached === true\n    }).length\n    const cacheHitRate = totalExecutions > 0 ? cachedCount / totalExecutions : 0\n    \n    // Tool breakdown\n    const toolBreakdown: Record<string, {\n      count: number\n      successes: number\n      durations: number[]\n    }> = {}\n    \n    data.forEach((log: { details: Json | null | undefined }) => {\n      const details = asJsonObject(log.details) as AuditLogDetails | undefined\n      const toolName = details?.toolName\n      if (toolName) {\n        if (!toolBreakdown[toolName]) {\n          toolBreakdown[toolName] = { count: 0, successes: 0, durations: [] }\n        }\n        toolBreakdown[toolName].count++\n        \n        if (details?.performance?.success === true) {\n          toolBreakdown[toolName].successes++\n        }\n        \n        const duration = details?.performance?.duration\n        if (typeof duration === 'number') {\n          toolBreakdown[toolName].durations.push(duration)\n        }\n      }\n    })\n    \n    // Calculate per-tool metrics\n    const toolMetrics: Record<string, {\n      count: number\n      successRate: number\n      averageDuration: number\n    }> = {}\n    \n    Object.entries(toolBreakdown).forEach(([toolName, data]) => {\n      toolMetrics[toolName] = {\n        count: data.count,\n        successRate: data.count > 0 ? data.successes / data.count : 0,\n        averageDuration: data.durations.length > 0\n          ? data.durations.reduce((a, b) => a + b, 0) / data.durations.length\n          : 0\n      }\n    })\n    \n    return {\n      totalExecutions,\n      successRate,\n      averageDuration,\n      cacheHitRate,\n      toolBreakdown: toolMetrics\n    }\n  }\n}\n\nexport const toolAnalytics = new ToolAnalyticsService()\n",
    "content2": "import { getSupabaseService } from '@/lib/supabase'\nimport type { ToolAnalytics } from './agent-analytics'\nimport { asJsonObject } from '../types/json-guards'\n\nconst DEFAULT_TOOL_ANALYTICS: ToolAnalytics = {\n  totalExecutions: 0,\n  successRate: 0,\n  averageDuration: 0,\n  cacheHitRate: 0,\n  toolBreakdown: {}\n}\n\ninterface AuditLogDetails {\n  toolName?: string\n  cached?: boolean\n  performance?: {\n    success?: boolean\n    duration?: number\n  }\n}\n\nexport class ToolAnalyticsService {\n  async getToolAnalytics(\n    timeRange?: { start: Date; end: Date }\n  ): Promise<ToolAnalytics> {\n    const supabase = getSupabaseService()\n    if (!supabase) {\n      console.warn('Supabase service unavailable - returning default tool analytics')\n      return DEFAULT_TOOL_ANALYTICS\n    }\n    \n    let query = supabase\n      .from('audit_log')\n      .select('*')\n      .eq('event', 'tool_executed')\n    \n    if (timeRange) {\n      query = query\n        .gte('timestamp', timeRange.start.toISOString())\n        .lte('timestamp', timeRange.end.toISOString())\n    }\n    \n    const { data, error } = await query\n    \n    if (error || !data) {\n      throw new Error(`Failed to fetch tool analytics: ${error?.message}`)\n    }\n    \n    const totalExecutions = data.length\n    const successCount = data.filter((log) => {\n      const details = asJsonObject(log.details) as AuditLogDetails | undefined\n      return details?.performance?.success === true\n    }).length\n    const successRate = totalExecutions > 0 ? successCount / totalExecutions : 0\n    \n    const durations = data\n      .map((log) => {\n        const details = asJsonObject(log.details) as AuditLogDetails | undefined\n        return details?.performance?.duration\n      })\n      .filter((d): d is number => typeof d === 'number')\n    const averageDuration = durations.length > 0 \n      ? durations.reduce((a: number, b: number) => a + b, 0) / durations.length \n      : 0\n    \n    const cachedCount = data.filter((log) => {\n      const details = asJsonObject(log.details) as AuditLogDetails | undefined\n      return details?.cached === true\n    }).length\n    const cacheHitRate = totalExecutions > 0 ? cachedCount / totalExecutions : 0\n    \n    // Tool breakdown\n    const toolBreakdown: Record<string, {\n      count: number\n      successes: number\n      durations: number[]\n    }> = {}\n    \n    data.forEach((log) => {\n      const details = asJsonObject(log.details) as AuditLogDetails | undefined\n      const toolName = details?.toolName\n      if (toolName) {\n        if (!toolBreakdown[toolName]) {\n          toolBreakdown[toolName] = { count: 0, successes: 0, durations: [] }\n        }\n        toolBreakdown[toolName].count++\n        \n        if (details?.performance?.success === true) {\n          toolBreakdown[toolName].successes++\n        }\n        \n        const duration = details?.performance?.duration\n        if (typeof duration === 'number') {\n          toolBreakdown[toolName].durations.push(duration)\n        }\n      }\n    })\n    \n    // Calculate per-tool metrics\n    const toolMetrics: Record<string, {\n      count: number\n      successRate: number\n      averageDuration: number\n    }> = {}\n    \n    Object.entries(toolBreakdown).forEach(([toolName, data]) => {\n      toolMetrics[toolName] = {\n        count: data.count,\n        successRate: data.count > 0 ? data.successes / data.count : 0,\n        averageDuration: data.durations.length > 0\n          ? data.durations.reduce((a, b) => a + b, 0) / data.durations.length\n          : 0\n      }\n    })\n    \n    return {\n      totalExecutions,\n      successRate,\n      averageDuration,\n      cacheHitRate,\n      toolBreakdown: toolMetrics\n    }\n  }\n}\n\nexport const toolAnalytics = new ToolAnalyticsService()\n"
  },
  "supabase/client": {
    "status": "different",
    "differences": [
      "Types only in source: assertion"
    ],
    "stats": {
      "source": {
        "lines": 192,
        "exports": 3,
        "functions": 7,
        "classes": 0
      },
      "target": {
        "lines": 187,
        "exports": 3,
        "functions": 7,
        "classes": 0
      }
    },
    "content1": "import { getSupabaseServer, getSupabaseService } from '../lib/supabase.js';\nimport { Database } from './database.types.js'\n\n// Type definitions for Supabase operations\ninterface SupabaseAuthUser {\n  id: string\n  email?: string\n  [key: string]: unknown\n}\n\ninterface SupabaseError {\n  code: string\n  message: string\n  details?: string\n  name?: string\n}\n\n// Type-safe Supabase client setup\nexport const supabase = getSupabaseServer();\n\n// Service Role Client for API operations (bypasses RLS) - only available server-side\nexport const supabaseService = getSupabaseService();\n\n// Safe authentication utility for server-side API routes\nexport async function getSafeUser(): Promise<{ user: SupabaseAuthUser | null; error: Error | null }> {\n  try {\n    // In server-side API routes, get the session first (which contains the user)\n    // Use type assertion since getSession() exists at runtime but types may be incomplete\n    const { data: { session }, error: sessionError } = await (supabase.auth as any).getSession()\n    if (sessionError) {\n      return { user: null, error: sessionError }\n    }\n    \n    // Extract user from session\n    const user = session?.user || null\n    return { user: user as SupabaseAuthUser | null, error: null }\n  } catch (error) {\n    // Handle AuthSessionMissingError gracefully - this is expected in server-side API routes\n    if (error && typeof error === 'object' && 'name' in error && (error as SupabaseError).name === 'AuthSessionMissingError') {\n      // This is expected behavior in server-side API routes\n      return { user: null, error: null }\n    }\n    return { user: null, error: error as Error }\n  }\n}\n\n// Type-safe Lead Creation Function\nexport async function createLeadSummary(\n  leadData: Database['public']['Tables']['lead_summaries']['Insert']\n) {\n  // Get current authenticated user safely\n  const { user, error: userError } = await getSafeUser()\n\n  if (userError) {\n    throw userError\n  }\n\n  if (!user) {\n    console.warn('createLeadSummary called without authenticated user context')\n  }\n\n  // Automatically set user_id if not provided\n  const finalLeadData = {\n    ...leadData,\n    user_id: leadData.user_id || user?.id || null\n  }\n\n  // Use service role client for API operations (bypasses RLS)\n  const { data, error } = await supabaseService\n    .from('lead_summaries')\n    .insert(finalLeadData)\n    .select()\n    .single()\n\n  if (error) {\n    // Error: Lead creation error\n    throw error\n  }\n\n  return data\n}\n\n// Comprehensive Error Handling\nexport function handleSupabaseError(error: SupabaseError): { message: string; code: string; details: string } {\n  const errorMap: Record<string, string> = {\n    'PGRST116': 'Permission denied. Check user authentication.',\n    'PGRST000': 'Database operation failed',\n    '23505': 'Unique constraint violation',\n    '23503': 'Foreign key constraint violation',\n    '42501': 'Row-level security policy violation',\n    '42P01': 'Table does not exist'\n  }\n\n  const errorMessage = errorMap[error.code] || 'Unexpected database error'\n\n  console.error({\n    message: errorMessage,\n    code: error.code,\n    details: error.message,\n    context: error\n  })\n\n  return {\n    message: errorMessage,\n    code: error.code,\n    details: error.message\n  }\n}\n\n// Type-safe search results creation\nexport async function createSearchResults(\n  leadId: string,\n  results: Array<{ url: string; title?: string; snippet?: string; source: string }>\n) {\n  if (results.length === 0) {\n    // Action logged\n    return []\n  }\n\n  const searchRecords = results.map(result => ({\n    lead_id: leadId,\n    source: result.source,\n    url: result.url,\n    title: result.title || '',\n    snippet: result.snippet || '',\n    raw: result\n  }))\n\n  const { data, error } = await supabaseService\n    .from('lead_search_results')\n    .insert(searchRecords)\n    .select()\n\n  if (error) {\n    // Error: Failed to store search results\n    throw error\n  }\n\n  // Action logged\n  return data || []\n}\n\n// Get search results for a lead\nexport async function getSearchResults(leadId: string) {\n  const { data, error } = await supabaseService\n    .from('lead_search_results')\n    .select('*')\n    .eq('lead_id', leadId)\n    .order('created_at', { ascending: false })\n\n  if (error) {\n    // Error: Failed to fetch search results\n    throw error\n  }\n\n  return data || []\n}\n\n// Get leads for the current user\nexport async function getUserLeads() {\n  const { data, error } = await supabase\n    .from('lead_summaries')\n    .select('*')\n    .order('created_at', { ascending: false })\n\n  if (error) {\n    // Error: Get user leads error\n    throw error\n  }\n\n  return data || []\n}\n\n// Get a specific lead by ID\nexport async function getLeadById(id: string) {\n  const { data, error } = await supabaseService\n    .from('lead_summaries')\n    .select('*')\n    .eq('id', id)\n    .single()\n\n  if (error) {\n    if (error.code === 'PGRST116') {\n      return null // Lead not found\n    }\n    console.error('Get lead error', error)\n    throw error\n  }\n\n  return data\n}\n",
    "content2": "import { getSupabaseServer, getSupabaseService } from '../../lib/supabase';\nimport { Database } from '../database.types'\n\n// Type definitions for Supabase operations\ninterface SupabaseAuthUser {\n  id: string\n  email?: string\n  [key: string]: unknown\n}\n\ninterface SupabaseError {\n  code: string\n  message: string\n  details?: string\n  name?: string\n}\n\n// Type-safe Supabase client setup\nexport const supabase = getSupabaseServer();\n\n// Service Role Client for API operations (bypasses RLS) - only available server-side\nexport const supabaseService = getSupabaseService();\n\n// Safe authentication utility for server-side API routes\nexport async function getSafeUser(): Promise<{ user: SupabaseAuthUser | null; error: Error | null }> {\n  try {\n    const { data: { user }, error } = await supabase.auth.getUser()\n    if (error) {\n      return { user: null, error }\n    }\n    return { user: user as SupabaseAuthUser | null, error: null }\n  } catch (error) {\n    // Handle AuthSessionMissingError gracefully - this is expected in server-side API routes\n    if (error && typeof error === 'object' && 'name' in error && (error as SupabaseError).name === 'AuthSessionMissingError') {\n      // This is expected behavior in server-side API routes\n      return { user: null, error: null }\n    }\n    return { user: null, error: error as Error }\n  }\n}\n\n// Type-safe Lead Creation Function\nexport async function createLeadSummary(\n  leadData: Database['public']['Tables']['lead_summaries']['Insert']\n) {\n  // Get current authenticated user safely\n  const { user, error: userError } = await getSafeUser()\n\n  if (userError) {\n    throw userError\n  }\n\n  if (!user) {\n    console.warn('createLeadSummary called without authenticated user context')\n  }\n\n  // Automatically set user_id if not provided\n  const finalLeadData = {\n    ...leadData,\n    user_id: leadData.user_id || user?.id || null\n  }\n\n  // Use service role client for API operations (bypasses RLS)\n  const { data, error } = await supabaseService\n    .from('lead_summaries')\n    .insert(finalLeadData)\n    .select()\n    .single()\n\n  if (error) {\n    // Error: Lead creation error\n    throw error\n  }\n\n  return data\n}\n\n// Comprehensive Error Handling\nexport function handleSupabaseError(error: SupabaseError): { message: string; code: string; details: string } {\n  const errorMap: Record<string, string> = {\n    'PGRST116': 'Permission denied. Check user authentication.',\n    'PGRST000': 'Database operation failed',\n    '23505': 'Unique constraint violation',\n    '23503': 'Foreign key constraint violation',\n    '42501': 'Row-level security policy violation',\n    '42P01': 'Table does not exist'\n  }\n\n  const errorMessage = errorMap[error.code] || 'Unexpected database error'\n\n  console.error({\n    message: errorMessage,\n    code: error.code,\n    details: error.message,\n    context: error\n  })\n\n  return {\n    message: errorMessage,\n    code: error.code,\n    details: error.message\n  }\n}\n\n// Type-safe search results creation\nexport async function createSearchResults(\n  leadId: string,\n  results: Array<{ url: string; title?: string; snippet?: string; source: string }>\n) {\n  if (results.length === 0) {\n    // Action logged\n    return []\n  }\n\n  const searchRecords = results.map(result => ({\n    lead_id: leadId,\n    source: result.source,\n    url: result.url,\n    title: result.title || '',\n    snippet: result.snippet || '',\n    raw: result\n  }))\n\n  const { data, error } = await supabaseService\n    .from('lead_search_results')\n    .insert(searchRecords)\n    .select()\n\n  if (error) {\n    // Error: Failed to store search results\n    throw error\n  }\n\n  // Action logged\n  return data || []\n}\n\n// Get search results for a lead\nexport async function getSearchResults(leadId: string) {\n  const { data, error } = await supabaseService\n    .from('lead_search_results')\n    .select('*')\n    .eq('lead_id', leadId)\n    .order('created_at', { ascending: false })\n\n  if (error) {\n    // Error: Failed to fetch search results\n    throw error\n  }\n\n  return data || []\n}\n\n// Get leads for the current user\nexport async function getUserLeads() {\n  const { data, error } = await supabase\n    .from('lead_summaries')\n    .select('*')\n    .order('created_at', { ascending: false })\n\n  if (error) {\n    // Error: Get user leads error\n    throw error\n  }\n\n  return data || []\n}\n\n// Get a specific lead by ID\nexport async function getLeadById(id: string) {\n  const { data, error } = await supabaseService\n    .from('lead_summaries')\n    .select('*')\n    .eq('id', id)\n    .single()\n\n  if (error) {\n    if (error.code === 'PGRST116') {\n      return null // Lead not found\n    }\n    console.error('Get lead error', error)\n    throw error\n  }\n\n  return data\n}\n"
  },
  "config/constants": {
    "status": "different",
    "differences": [
      "Functions only in target: isLocalhostRuntime",
      "Significant line count difference: 393 vs 432 lines"
    ],
    "stats": {
      "source": {
        "lines": 393,
        "exports": 23,
        "functions": 4,
        "classes": 0
      },
      "target": {
        "lines": 432,
        "exports": 23,
        "functions": 5,
        "classes": 0
      }
    },
    "content1": "/**\n * CENTRALIZED CONFIGURATION\n * DO NOT HARDCODE THESE VALUES ANYWHERE ELSE\n * \n * All WebSocket URLs, model names, and other configuration values\n * must be imported from this file.\n */\n\nconst trimTrailingSlash = (value: string) => value.replace(/\\/+$/, '')\n\nconst normalizeWebsocketUrl = (\n  rawValue: string | undefined,\n  {\n    fallback,\n    enforceSecure = false,\n  }: {\n    fallback: string\n    enforceSecure?: boolean\n  }\n) => {\n  if (!rawValue) {\n    return trimTrailingSlash(fallback)\n  }\n\n  try {\n    const trimmed = rawValue.trim()\n    const hasScheme = /^[a-z]+:\\/\\//i.test(trimmed)\n    const baseProtocol = enforceSecure ? 'wss://' : 'ws://'\n    const candidate = hasScheme ? trimmed : `${baseProtocol}${trimmed}`\n    const url = new URL(candidate)\n\n    if (url.protocol === 'http:') url.protocol = 'ws:'\n    if (url.protocol === 'https:') url.protocol = 'wss:'\n    if (enforceSecure && url.protocol !== 'wss:') {\n      url.protocol = 'wss:'\n    }\n\n    const hostname = url.hostname.toLowerCase()\n    const isLocalHost =\n      hostname === 'localhost' ||\n      hostname === '127.0.0.1' ||\n      hostname === '[::1]' ||\n      hostname.endsWith('.local') ||\n      hostname.endsWith('.localdomain')\n\n    if (!isLocalHost && url.protocol === 'wss:') {\n      if (url.port && url.port !== '443') {\n        console.warn(\n          `[WEBSOCKET_CONFIG] Stripping unsupported secure port \"${url.port}\" from ${url.hostname}`\n        )\n        url.port = ''\n      }\n    }\n\n    return trimTrailingSlash(url.toString())\n  } catch (error) {\n    console.warn(\n      '[WEBSOCKET_CONFIG] Invalid WebSocket URL provided; falling back to default',\n      error\n    )\n    return trimTrailingSlash(fallback)\n  }\n}\n\n// WebSocket Configuration\n// Check if we're in production at runtime (client-side aware)\nconst isProductionRuntime = () => {\n  // Server-side: use NODE_ENV\n  if (typeof window === 'undefined') {\n    return process.env.NODE_ENV === 'production'\n  }\n  // Client-side: check hostname to detect production domains\n  const hostname = typeof window !== 'undefined' ? window.location.hostname : ''\n  const isLocalhost =\n    hostname === 'localhost' ||\n    hostname === '127.0.0.1' ||\n    hostname === '[::1]' ||\n    hostname.endsWith('.local') ||\n    hostname.endsWith('.localdomain') ||\n    hostname.includes('.local')\n  return !isLocalhost && !hostname.includes('vercel.app')\n}\n\nexport const WEBSOCKET_CONFIG = {\n  // Distinct envs for prod vs dev to avoid accidental overrides\n  PRODUCTION_URL: normalizeWebsocketUrl(process.env.NEXT_PUBLIC_LIVE_SERVER_URL, {\n    fallback: 'wss://fb-consulting-websocket.fly.dev',\n    enforceSecure: true,\n  }),\n  DEVELOPMENT_URL: normalizeWebsocketUrl(process.env.NEXT_PUBLIC_LIVE_SERVER_DEV_URL, {\n    fallback: 'ws://localhost:3001',\n  }),\n  get URL() {\n    // Runtime check for production\n    if (isProductionRuntime()) {\n      return this.PRODUCTION_URL\n    }\n    // Prefer explicit dev URL when present\n    if (process.env.NEXT_PUBLIC_LIVE_SERVER_DEV_URL) return this.DEVELOPMENT_URL\n    // Derive from current host in the browser for local networks\n    if (typeof window !== 'undefined') {\n      const host = window.location.hostname\n      const isSecure = typeof window !== 'undefined' && window.location.protocol === 'https:'\n      const protocol = isSecure ? 'wss' : 'ws'\n      // WebSocket server runs on 3001, NOT the same port as Next.js (3000)\n      const port = process.env.NEXT_PUBLIC_LIVE_SERVER_DEV_PORT ?? '3001'\n      const portSuffix = port ? `:${port}` : ''\n      return `${protocol}://${host}${portSuffix}`\n    }\n    return this.DEVELOPMENT_URL\n  },\n  RECONNECT_DELAY: 3000,\n  MAX_RECONNECT_ATTEMPTS: 5,\n  HEARTBEAT_INTERVAL: 30000, // 30 seconds\n  MAX_BUFFERED_AMOUNT: 500_000, // 500KB - buffer threshold for client\n  HEARTBEAT_TIMEOUT_MS: 45000, // Allow 45 seconds to accommodate server heartbeat interval\n  FRAME_QUEUE_MAX_SIZE: 5,\n  FRAME_QUEUE_PROCESS_INTERVAL: 500, // ms\n  LOW_QUALITY_JPEG: 0.75,\n  HIGH_BUFFER_THRESHOLD: 300_000, // 300KB - start reducing quality\n} as const\n\n// Gemini Model Names\nexport const GEMINI_MODELS = {\n  // NEW: Google's latest models (auto-update to newest)\n  FLASH_LATEST: 'gemini-flash-latest',              // Auto-updates to latest Flash\n  FLASH_LITE_LATEST: 'gemini-flash-lite-latest',    // Auto-updates to latest Lite\n\n  // NEW: Specific versions (predictable behavior)\n  FLASH_2025_09: 'gemini-2.5-flash-preview-09-2025',\n  FLASH_LITE_2025_09: 'gemini-2.5-flash-lite-preview-09-2025',\n  AUDIO_2025_09: 'gemini-live-2.5-flash-preview-native-audio-09-2025', // Live API native audio model (v7 compatible)\n\n  // NEW: Gemini 3.0\n  GEMINI_3_PRO_PREVIEW: 'gemini-3-pro-preview',\n\n  // LEGACY: For backward compatibility (deprecated models)\n\n  FLASH_EXP: 'gemini-2.0-flash-exp',                // Old experimental\n\n  // DEFAULTS: What each use case should use\n  DEFAULT_CHAT: 'gemini-flash-latest',               // Auto-updates to best\n  DEFAULT_VOICE: 'gemini-live-2.5-flash-preview-native-audio-09-2025', // Live API native audio (updated model name)\n  DEFAULT_MULTIMODAL: 'gemini-flash-latest',         // Best for images/video\n  DEFAULT_WEBCAM: 'gemini-flash-latest',             // Webcam analysis\n  DEFAULT_SCREEN: 'gemini-flash-latest',             // Screen capture\n  DEFAULT_FAST: 'gemini-flash-lite-latest',          // When speed matters\n  DEFAULT_RELIABLE: 'gemini-2.5-flash-preview-09-2025', // When predictability matters\n} as const\n\n// Gemini API Endpoints\nexport const GEMINI_ENDPOINTS = {\n  LIVE_API: 'generativelanguage.googleapis.com/v1beta/models',\n  STANDARD_API: 'generativelanguage.googleapis.com/v1/models',\n  STREAMING_API: 'generativelanguage.googleapis.com/v1beta/models',\n  V1_ALPHA_API: 'generativelanguage.googleapis.com/v1alpha/models', // Required for Gemini 3 features like media_resolution\n} as const\n\n// Embedding Models\nexport const EMBEDDING_MODELS = {\n  DEFAULT: 'text-embedding-004',\n  TEXT_EMBEDDING_004: 'text-embedding-004',\n} as const\n\n// Gemini 3.0 Specific Configurations\nexport const THINKING_LEVELS = {\n  LOW: 'low',\n  HIGH: 'high', // Default for Gemini 3\n} as const\n\nexport const MEDIA_RESOLUTIONS = {\n  LOW: 'media_resolution_low',\n  MEDIUM: 'media_resolution_medium',\n  HIGH: 'media_resolution_high',\n} as const\n\n// Gemini Live API Configuration\nexport const LIVE_API_CONFIG = {\n  // Use sendRealtimeInput(), NOT session.send()\n  METHOD_NAME: 'sendRealtimeInput',\n  AUDIO_ENCODING: 'pcm_s16le',\n  SAMPLE_RATE: 24000,\n  CHANNELS: 1,\n} as const\n\n// Type safety\nexport type GeminiModel = typeof GEMINI_MODELS[keyof typeof GEMINI_MODELS]\nexport type GeminiEndpoint = typeof GEMINI_ENDPOINTS[keyof typeof GEMINI_ENDPOINTS]\n\n// API Rate Limits\nexport const RATE_LIMITS = {\n  WEBCAM_CAPTURE_INTERVAL: 2000, // 2 seconds (for analysis, not streaming)\n  SCREEN_CAPTURE_INTERVAL: 2000, // 2 seconds (for analysis, not streaming)\n  // Live API streaming intervals - much longer to avoid overwhelming the API\n  WEBCAM_STREAM_INTERVAL: 1000, // 1 second - faster for real-time feel\n  SCREEN_STREAM_INTERVAL: 1000, // 1 second - faster for real-time feel\n} as const\n\n// Context Configuration\nexport const CONTEXT_CONFIG = {\n  REDIS_TTL: 3600, // 1 hour for active sessions\n  ARCHIVE_ON_DISCONNECT: true,\n  AUTO_GENERATE_PDF: true,\n  MIN_MESSAGES_FOR_ARCHIVE: 3, // Don't archive test conversations\n  SUMMARIZE_THRESHOLD: 50, // Summarize every 50 messages\n} as const\n\n// Security Configuration\nexport const SECURITY_CONFIG = {\n  ENABLE_PII_DETECTION: process.env.NODE_ENV === 'production',\n  ENABLE_PII_REDACTION: process.env.NODE_ENV === 'production',\n  ENABLE_AUDIT_LOGGING: true,\n  DATA_RETENTION_DAYS: 90, // GDPR compliance\n  ENABLE_ENCRYPTION_AT_REST: true, // For Supabase\n} as const\n\n// Session Configuration\nexport const SESSION_CONFIG = {\n  TIMEOUT: 30 * 60 * 1000, // 30 minutes\n  WARNING_THRESHOLD: 25 * 60 * 1000, // 25 minutes\n  HEARTBEAT_INTERVAL: 60 * 1000, // 1 minute\n} as const\n\n// Audio Configuration\nexport const AUDIO_CONFIG = {\n  SAMPLE_RATE: 24000,\n  CHANNELS: 1,\n  BIT_DEPTH: 16,\n  CHUNK_SIZE: 4096,\n  NOISE_GATE_THRESHOLD: -50, // dB\n} as const\n\n// Security / CORS\nexport const ALLOWED_ORIGINS = (\n  process.env.NEXT_PUBLIC_ALLOWED_ORIGINS ||\n  [\n    'https://fbcai.com',\n    'https://farzadbayat.com',\n    'https://www.farzadbayat.com',\n    'http://localhost:3000',\n    'http://localhost:3001',\n    'http://127.0.0.1:3000',\n    'http://127.0.0.1:3001',\n  ].join(',')\n)\n  .split(',')\n  .map((s) => s.trim())\n  .filter(Boolean)\n\n// Third-party API endpoints\nexport const EXTERNAL_ENDPOINTS = {\n  RESEND_EMAIL: process.env.NEXT_PUBLIC_RESEND_API_ENDPOINT || 'https://api.resend.com/emails',\n  PERPLEXITY_CHAT_COMPLETIONS:\n    process.env.NEXT_PUBLIC_PERPLEXITY_API_ENDPOINT || 'https://api.perplexity.ai/chat/completions',\n} as const\n\n// Contact details & scheduling configuration\nconst schedulingUsername = process.env.NEXT_PUBLIC_SCHEDULING_USERNAME || 'farzad-bayat'\nconst schedulingEvent = process.env.NEXT_PUBLIC_SCHEDULING_EVENT || '30min'\nconst schedulingBaseUrl = trimTrailingSlash(\n  process.env.NEXT_PUBLIC_SCHEDULING_BASE_URL || 'https://cal.com',\n)\nconst schedulingEmbedBaseUrl = trimTrailingSlash(\n  process.env.NEXT_PUBLIC_SCHEDULING_EMBED_BASE_URL || 'https://app.cal.com',\n)\nconst schedulingEmbedScript =\n  process.env.NEXT_PUBLIC_SCHEDULING_EMBED_SCRIPT || 'https://app.cal.com/embed/embed.js'\n\nexport const CONTACT_CONFIG = {\n  SUPPORT_EMAIL: process.env.NEXT_PUBLIC_CONTACT_EMAIL || 'farzad@fbc.ai',\n  WEBSITE_URL: process.env.NEXT_PUBLIC_WEBSITE_URL || 'https://fbc.ai',\n  DEFAULT_FROM_EMAIL: process.env.RESEND_FROM_EMAIL || 'F.B/c <contact@farzadbayat.com>',\n  SCHEDULING: {\n    USERNAME: schedulingUsername,\n    EVENT: schedulingEvent,\n    BOOKING_URL: `${schedulingBaseUrl}/${schedulingUsername}/${schedulingEvent}`,\n    EMBED_URL: `${schedulingEmbedBaseUrl}/${schedulingUsername}/${schedulingEvent}?embed=true`,\n    EMBED_SCRIPT_SRC: schedulingEmbedScript,\n    BASE_URL: schedulingBaseUrl,\n    EMBED_BASE_URL: schedulingEmbedBaseUrl,\n  },\n} as const\n\n// Voice System Configuration\nexport const VOICE_CONFIG = {\n  BY_LANG: {\n    'en-US': 'Puck',\n    'en-GB': 'Puck',\n    'nb-NO': 'Puck',\n    'sv-SE': 'Puck',\n    'de-DE': 'Puck',\n    'es-ES': 'Puck',\n  } as const,\n  DEFAULT_VOICE: 'Puck',\n  VISUAL_TRIGGERS: (process.env.LIVE_SERVER_VISUAL_TRIGGERS || 'screen,showing,look at,see this,dashboard,workflow')\n    .split(',')\n    .map(s => s.trim().toLowerCase())\n    .filter(Boolean),\n  VISUAL_INJECT_THROTTLE_MS: Math.max(\n    0,\n    Number.parseInt(process.env.LIVE_SERVER_VISUAL_INJECT_THROTTLE_MS || '8000', 10) || 8000\n  ),\n  CONTEXT_INJECT_DEBOUNCE_MS: Math.max(\n    0,\n    Number.parseInt(process.env.LIVE_SERVER_CONTEXT_INJECT_DEBOUNCE_MS || '600', 10) || 600\n  ),\n  INJECT_ON_CONTEXT_UPDATE: process.env.LIVE_SERVER_INJECT_ON_CONTEXT_UPDATE === '0' ? false : true,\n} as const\n\n// Gemini Configuration\nexport const GEMINI_CONFIG = {\n  DEFAULT_TEMPERATURE: 0.7,\n  MAX_TOKENS: 8192,\n  SYSTEM_PROMPT: `You are F.B/c, Farzad Bayat's sharp, friendly consulting assistant.\n- Speak concisely (2 sentences max by default).\n- Ask one focused question when you need more context.\n- Keep a natural voice tone; avoid lists unless asked.\n- You have VISUAL CAPABILITIES: You can see webcam and screen share video frames in real-time.\n- When you receive video input, acknowledge what you see and provide relevant insights.\nPronunciation: \"Farzad Bayat\" ~ \"Fahrâ€“zahd Byeâ€“yaht\" (soft 'a' in Farzad).`,\n} as const\n\n// Feature Flags\nexport const FEATURE_FLAGS = {\n  REASONING_STREAMING:\n    (process.env.NEXT_PUBLIC_FEATURE_REASONING_STREAMING || '0').toLowerCase() === '1' ||\n    (process.env.NEXT_PUBLIC_FEATURE_REASONING_STREAMING || '').toLowerCase() === 'true',\n  SHOW_VOICE_OVERLAY:\n    (process.env.NEXT_PUBLIC_FEATURE_VOICE_OVERLAY || '1').toLowerCase() === '1' ||\n    (process.env.NEXT_PUBLIC_FEATURE_VOICE_OVERLAY || '').toLowerCase() === 'true',\n  SHOW_USAGE_CARD:\n    (process.env.NEXT_PUBLIC_FEATURE_SHOW_USAGE_CARD || '0').toLowerCase() === '1' ||\n    (process.env.NEXT_PUBLIC_FEATURE_SHOW_USAGE_CARD || '').toLowerCase() === 'true',\n  // Controls whether the primary chat experience is the dedicated /live page\n} as const\n\n// Agent Stage Configuration - User-friendly stage descriptions\nexport const AGENT_STAGE_CONFIG = {\n  DISCOVERY: {\n    label: \"Discovery\",\n    description: \"Understanding your business needs and goals\",\n    order: 1\n  },\n  SCORING: {\n    label: \"Analysis\",\n    description: \"Evaluating solution fit for your situation\",\n    order: 2\n  },\n  WORKSHOP_PITCH: {\n    label: \"Workshop Solution\",\n    description: \"Designing training approach for your team\",\n    order: 3\n  },\n  CONSULTING_PITCH: {\n    label: \"Custom Solution\",\n    description: \"Architecting enterprise AI implementation\",\n    order: 3\n  },\n  CLOSING: {\n    label: \"Proposal\",\n    description: \"Finalizing next steps and addressing questions\",\n    order: 4\n  },\n  SUMMARY: {\n    label: \"Summary\",\n    description: \"Preparing your personalized strategy report\",\n    order: 5\n  }\n} as const\n\n// Agent UI Configuration (canonical)\nexport const AGENT_UI_CONFIG = {\n  websocketUrl: WEBSOCKET_CONFIG.URL,\n  features: {\n    voice: true,\n    video: true,\n    screenShare: true,\n    chat: true,\n    transcripts: true,\n  },\n  reconnectAttempts: WEBSOCKET_CONFIG.MAX_RECONNECT_ATTEMPTS,\n  reconnectDelay: WEBSOCKET_CONFIG.RECONNECT_DELAY,\n  isPreConnectBufferEnabled: true,\n  agentName: 'fbc-agent',\n  model: GEMINI_MODELS.DEFAULT_VOICE,\n} as const\n\n// Admin Configuration\nexport const ADMIN_CONFIG = {\n  ADMIN_ID: 'farzad',\n  ADMIN_EMAIL: 'farzad@bayatconsulting.com',\n} as const\n",
    "content2": "/**\n * CENTRALIZED CONFIGURATION\n * DO NOT HARDCODE THESE VALUES ANYWHERE ELSE\n * \n * All WebSocket URLs, model names, and other configuration values\n * must be imported from this file.\n */\n\nconst trimTrailingSlash = (value: string) => value.replace(/\\/+$/, '')\n\nconst normalizeWebsocketUrl = (\n  rawValue: string | undefined,\n  {\n    fallback,\n    enforceSecure = false,\n  }: {\n    fallback: string\n    enforceSecure?: boolean\n  }\n) => {\n  if (!rawValue) {\n    return trimTrailingSlash(fallback)\n  }\n\n  try {\n    const trimmed = rawValue.trim()\n    const hasScheme = /^[a-z]+:\\/\\//i.test(trimmed)\n    const baseProtocol = enforceSecure ? 'wss://' : 'ws://'\n    const candidate = hasScheme ? trimmed : `${baseProtocol}${trimmed}`\n    const url = new URL(candidate)\n\n    if (url.protocol === 'http:') url.protocol = 'ws:'\n    if (url.protocol === 'https:') url.protocol = 'wss:'\n    if (enforceSecure && url.protocol !== 'wss:') {\n      url.protocol = 'wss:'\n    }\n\n    const hostname = url.hostname.toLowerCase()\n    const isLocalHost =\n      hostname === 'localhost' ||\n      hostname === '127.0.0.1' ||\n      hostname === '[::1]' ||\n      hostname.endsWith('.local') ||\n      hostname.endsWith('.localdomain')\n\n    if (!isLocalHost && url.protocol === 'wss:') {\n      if (url.port && url.port !== '443') {\n        console.warn(\n          `[WEBSOCKET_CONFIG] Stripping unsupported secure port \"${url.port}\" from ${url.hostname}`\n        )\n        url.port = ''\n      }\n    }\n\n    return trimTrailingSlash(url.toString())\n  } catch (error) {\n    console.warn(\n      '[WEBSOCKET_CONFIG] Invalid WebSocket URL provided; falling back to default',\n      error\n    )\n    return trimTrailingSlash(fallback)\n  }\n}\n\n// WebSocket Configuration\n// Check if we're running locally (client-side aware)\nconst isLocalhostRuntime = () => {\n  // Server-side: check NODE_ENV\n  if (typeof window === 'undefined') {\n    return process.env.NODE_ENV !== 'production'\n  }\n  \n  // Client-side: check hostname to detect localhost\n  const hostname = typeof window !== 'undefined' ? window.location.hostname : ''\n  return (\n    hostname === 'localhost' ||\n    hostname === '127.0.0.1' ||\n    hostname === '[::1]' ||\n    hostname.endsWith('.local') ||\n    hostname.endsWith('.localdomain') ||\n    hostname.includes('.local')\n  )\n}\n\n// Check if we're in production at runtime (client-side aware)\nconst isProductionRuntime = () => {\n  // Always use localhost when running locally, even if NEXT_PUBLIC_LIVE_SERVER_URL is set\n  if (isLocalhostRuntime()) {\n    return false\n  }\n  \n  // If NEXT_PUBLIC_LIVE_SERVER_URL is explicitly set and we're not on localhost, use it\n  if (process.env.NEXT_PUBLIC_LIVE_SERVER_URL) {\n    return true\n  }\n  \n  // Server-side: use NODE_ENV\n  if (typeof window === 'undefined') {\n    return process.env.NODE_ENV === 'production'\n  }\n  \n  // Client-side: production if not localhost (includes vercel.app, custom domains, etc.)\n  return true // We already checked for localhost above\n}\n\nexport const WEBSOCKET_CONFIG = {\n  // Distinct envs for prod vs dev to avoid accidental overrides\n  PRODUCTION_URL: normalizeWebsocketUrl(process.env.NEXT_PUBLIC_LIVE_SERVER_URL, {\n    fallback: 'wss://fb-consulting-websocket.fly.dev',\n    enforceSecure: true,\n  }),\n  DEVELOPMENT_URL: normalizeWebsocketUrl(process.env.NEXT_PUBLIC_LIVE_SERVER_DEV_URL, {\n    fallback: 'ws://localhost:3001',\n  }),\n  get URL() {\n    // Always use localhost when running locally, even if NEXT_PUBLIC_LIVE_SERVER_URL is set\n    if (isLocalhostRuntime()) {\n      // Prefer explicit dev URL when present\n      if (process.env.NEXT_PUBLIC_LIVE_SERVER_DEV_URL) {\n        console.log('[WEBSOCKET_CONFIG] Using dev URL from NEXT_PUBLIC_LIVE_SERVER_DEV_URL:', this.DEVELOPMENT_URL)\n        return this.DEVELOPMENT_URL\n      }\n      \n      // Derive from current host in the browser for local networks\n      if (typeof window !== 'undefined') {\n        const host = window.location.hostname\n        const isSecure = typeof window !== 'undefined' && window.location.protocol === 'https:'\n        const protocol = isSecure ? 'wss' : 'ws'\n        // WebSocket server runs on 3001, NOT the same port as Next.js (3000)\n        const port = process.env.NEXT_PUBLIC_LIVE_SERVER_DEV_PORT ?? '3001'\n        const portSuffix = port ? `:${port}` : ''\n        const devUrl = `${protocol}://${host}${portSuffix}`\n        console.log('[WEBSOCKET_CONFIG] Using dev URL (local development):', devUrl)\n        return devUrl\n      }\n      \n      console.log('[WEBSOCKET_CONFIG] Using default dev URL (local development):', this.DEVELOPMENT_URL)\n      return this.DEVELOPMENT_URL\n    }\n    \n    // Production mode - use NEXT_PUBLIC_LIVE_SERVER_URL if set, otherwise fallback\n    if (process.env.NEXT_PUBLIC_LIVE_SERVER_URL) {\n      console.log('[WEBSOCKET_CONFIG] Using production URL from NEXT_PUBLIC_LIVE_SERVER_URL:', this.PRODUCTION_URL)\n      return this.PRODUCTION_URL\n    }\n    \n    // Production fallback\n    console.log('[WEBSOCKET_CONFIG] Using production URL (fallback):', this.PRODUCTION_URL)\n    return this.PRODUCTION_URL\n  },\n  RECONNECT_DELAY: 3000,\n  MAX_RECONNECT_ATTEMPTS: 5,\n  HEARTBEAT_INTERVAL: 30000, // 30 seconds\n  MAX_BUFFERED_AMOUNT: 500_000, // 500KB - buffer threshold for client\n  HEARTBEAT_TIMEOUT_MS: 45000, // Allow 45 seconds to accommodate server heartbeat interval\n  FRAME_QUEUE_MAX_SIZE: 5,\n  FRAME_QUEUE_PROCESS_INTERVAL: 500, // ms\n  LOW_QUALITY_JPEG: 0.75,\n  HIGH_BUFFER_THRESHOLD: 300_000, // 300KB - start reducing quality\n} as const\n\n// Gemini Model Names\nexport const GEMINI_MODELS = {\n  // NEW: Google's latest models (auto-update to newest)\n  FLASH_LATEST: 'gemini-2.5-flash',              // Auto-updates to latest Flash\n  FLASH_LITE_LATEST: 'gemini-2.5-flash-lite',    // Auto-updates to latest Lite\n\n  // NEW: Specific versions (predictable behavior)\n  FLASH_2025_09: 'gemini-2.5-flash',\n  FLASH_LITE_2025_09: 'gemini-2.5-flash-lite',\n  AUDIO_2025_09: 'gemini-2.5-flash-native-audio-preview-09-2025', // Live API native audio model\n\n  // NEW: Gemini 3.0\n  GEMINI_3_PRO_PREVIEW: 'gemini-3-pro-preview',\n\n  // LEGACY: For backward compatibility (deprecated models)\n\n  FLASH_EXP: 'gemini-2.0-flash-exp',                // Old experimental\n\n  // DEFAULTS: What each use case should use\n  DEFAULT_CHAT: 'gemini-3-pro-preview',               // Standard Chat\n  DEFAULT_VOICE: 'gemini-2.5-flash-native-audio-preview-09-2025', // Live Voice\n  DEFAULT_MULTIMODAL: 'gemini-3-pro-preview',         // Vision\n  DEFAULT_WEBCAM: 'gemini-3-pro-preview',             // Webcam analysis\n  DEFAULT_SCREEN: 'gemini-3-pro-preview',             // Screen capture\n  DEFAULT_FAST: 'gemini-2.5-flash-lite',          // Quick Edit\n  DEFAULT_RELIABLE: 'gemini-2.5-flash', // Research\n} as const\n\n// Gemini API Endpoints\nexport const GEMINI_ENDPOINTS = {\n  LIVE_API: 'generativelanguage.googleapis.com/v1beta/models',\n  STANDARD_API: 'generativelanguage.googleapis.com/v1/models',\n  STREAMING_API: 'generativelanguage.googleapis.com/v1beta/models',\n  V1_ALPHA_API: 'generativelanguage.googleapis.com/v1alpha/models', // Required for Gemini 3 features like media_resolution\n} as const\n\n// Embedding Models\nexport const EMBEDDING_MODELS = {\n  DEFAULT: 'text-embedding-004',\n  TEXT_EMBEDDING_004: 'text-embedding-004',\n} as const\n\n// Gemini 3.0 Specific Configurations\nexport const THINKING_LEVELS = {\n  LOW: 'low',\n  HIGH: 'high', // Default for Gemini 3\n} as const\n\nexport const MEDIA_RESOLUTIONS = {\n  LOW: 'media_resolution_low',\n  MEDIUM: 'media_resolution_medium',\n  HIGH: 'media_resolution_high',\n} as const\n\n// Gemini Live API Configuration\nexport const LIVE_API_CONFIG = {\n  // Use sendRealtimeInput(), NOT session.send()\n  METHOD_NAME: 'sendRealtimeInput',\n  AUDIO_ENCODING: 'pcm_s16le',\n  SAMPLE_RATE: 24000,\n  CHANNELS: 1,\n} as const\n\n// Type safety\nexport type GeminiModel = typeof GEMINI_MODELS[keyof typeof GEMINI_MODELS]\nexport type GeminiEndpoint = typeof GEMINI_ENDPOINTS[keyof typeof GEMINI_ENDPOINTS]\n\n// API Rate Limits\nexport const RATE_LIMITS = {\n  WEBCAM_CAPTURE_INTERVAL: 2000, // 2 seconds (for analysis, not streaming)\n  SCREEN_CAPTURE_INTERVAL: 2000, // 2 seconds (for analysis, not streaming)\n  // Live API streaming intervals - much longer to avoid overwhelming the API\n  WEBCAM_STREAM_INTERVAL: 1000, // 1 second - faster for real-time feel\n  SCREEN_STREAM_INTERVAL: 1000, // 1 second - faster for real-time feel\n} as const\n\n// Context Configuration\nexport const CONTEXT_CONFIG = {\n  REDIS_TTL: 3600, // 1 hour for active sessions\n  ARCHIVE_ON_DISCONNECT: true,\n  AUTO_GENERATE_PDF: true,\n  MIN_MESSAGES_FOR_ARCHIVE: 3, // Don't archive test conversations\n  SUMMARIZE_THRESHOLD: 50, // Summarize every 50 messages\n} as const\n\n// Security Configuration\nexport const SECURITY_CONFIG = {\n  ENABLE_PII_DETECTION: process.env.NODE_ENV === 'production',\n  ENABLE_PII_REDACTION: process.env.NODE_ENV === 'production',\n  ENABLE_AUDIT_LOGGING: true,\n  DATA_RETENTION_DAYS: 90, // GDPR compliance\n  ENABLE_ENCRYPTION_AT_REST: true, // For Supabase\n} as const\n\n// Session Configuration\nexport const SESSION_CONFIG = {\n  TIMEOUT: 30 * 60 * 1000, // 30 minutes\n  WARNING_THRESHOLD: 25 * 60 * 1000, // 25 minutes\n  HEARTBEAT_INTERVAL: 60 * 1000, // 1 minute\n} as const\n\n// Audio Configuration\nexport const AUDIO_CONFIG = {\n  SAMPLE_RATE: 24000,\n  CHANNELS: 1,\n  BIT_DEPTH: 16,\n  CHUNK_SIZE: 4096,\n  NOISE_GATE_THRESHOLD: -50, // dB\n} as const\n\n// Security / CORS\nexport const ALLOWED_ORIGINS = (\n  process.env.NEXT_PUBLIC_ALLOWED_ORIGINS ||\n  [\n    'https://fbcai.com',\n    'https://farzadbayat.com',\n    'https://www.farzadbayat.com',\n    'http://localhost:3000',\n    'http://localhost:3001',\n    'http://127.0.0.1:3000',\n    'http://127.0.0.1:3001',\n  ].join(',')\n)\n  .split(',')\n  .map((s) => s.trim())\n  .filter(Boolean)\n\n// Third-party API endpoints\nexport const EXTERNAL_ENDPOINTS = {\n  RESEND_EMAIL: process.env.NEXT_PUBLIC_RESEND_API_ENDPOINT || 'https://api.resend.com/emails',\n  PERPLEXITY_CHAT_COMPLETIONS:\n    process.env.NEXT_PUBLIC_PERPLEXITY_API_ENDPOINT || 'https://api.perplexity.ai/chat/completions',\n} as const\n\n// Contact details & scheduling configuration\nconst schedulingUsername = process.env.NEXT_PUBLIC_SCHEDULING_USERNAME || 'farzad-bayat'\nconst schedulingEvent = process.env.NEXT_PUBLIC_SCHEDULING_EVENT || '30min'\nconst schedulingBaseUrl = trimTrailingSlash(\n  process.env.NEXT_PUBLIC_SCHEDULING_BASE_URL || 'https://cal.com',\n)\nconst schedulingEmbedBaseUrl = trimTrailingSlash(\n  process.env.NEXT_PUBLIC_SCHEDULING_EMBED_BASE_URL || 'https://app.cal.com',\n)\nconst schedulingEmbedScript =\n  process.env.NEXT_PUBLIC_SCHEDULING_EMBED_SCRIPT || 'https://app.cal.com/embed/embed.js'\n\nexport const CONTACT_CONFIG = {\n  SUPPORT_EMAIL: process.env.NEXT_PUBLIC_CONTACT_EMAIL || 'farzad@fbc.ai',\n  WEBSITE_URL: process.env.NEXT_PUBLIC_WEBSITE_URL || 'https://fbc.ai',\n  DEFAULT_FROM_EMAIL: process.env.RESEND_FROM_EMAIL || 'F.B/c <contact@farzadbayat.com>',\n  SCHEDULING: {\n    USERNAME: schedulingUsername,\n    EVENT: schedulingEvent,\n    BOOKING_URL: `${schedulingBaseUrl}/${schedulingUsername}/${schedulingEvent}`,\n    EMBED_URL: `${schedulingEmbedBaseUrl}/${schedulingUsername}/${schedulingEvent}?embed=true`,\n    EMBED_SCRIPT_SRC: schedulingEmbedScript,\n    BASE_URL: schedulingBaseUrl,\n    EMBED_BASE_URL: schedulingEmbedBaseUrl,\n  },\n} as const\n\n// Voice System Configuration\nexport const VOICE_CONFIG = {\n  BY_LANG: {\n    'en-US': 'Puck',\n    'en-GB': 'Puck',\n    'nb-NO': 'Puck',\n    'sv-SE': 'Puck',\n    'de-DE': 'Puck',\n    'es-ES': 'Puck',\n  } as const,\n  DEFAULT_VOICE: 'Puck',\n  VISUAL_TRIGGERS: (process.env.LIVE_SERVER_VISUAL_TRIGGERS || 'screen,showing,look at,see this,dashboard,workflow')\n    .split(',')\n    .map(s => s.trim().toLowerCase())\n    .filter(Boolean),\n  VISUAL_INJECT_THROTTLE_MS: Math.max(\n    0,\n    Number.parseInt(process.env.LIVE_SERVER_VISUAL_INJECT_THROTTLE_MS || '8000', 10) || 8000\n  ),\n  CONTEXT_INJECT_DEBOUNCE_MS: Math.max(\n    0,\n    Number.parseInt(process.env.LIVE_SERVER_CONTEXT_INJECT_DEBOUNCE_MS || '600', 10) || 600\n  ),\n  INJECT_ON_CONTEXT_UPDATE: process.env.LIVE_SERVER_INJECT_ON_CONTEXT_UPDATE === '0' ? false : true,\n} as const\n\n// Gemini Configuration\nexport const GEMINI_CONFIG = {\n  DEFAULT_TEMPERATURE: 0.7,\n  MAX_TOKENS: 8192,\n  SYSTEM_PROMPT: `You are F.B/c, Farzad Bayat's sharp, friendly consulting assistant.\n- Speak concisely (2 sentences max by default).\n- Ask one focused question when you need more context.\n- Keep a natural voice tone; avoid lists unless asked.\n- You have VISUAL CAPABILITIES: You can see webcam and screen share video frames in real-time.\n- When you receive video input, acknowledge what you see and provide relevant insights.\nPronunciation: \"Farzad Bayat\" ~ \"Fahrâ€“zahd Byeâ€“yaht\" (soft 'a' in Farzad).`,\n} as const\n\n// Feature Flags\nexport const FEATURE_FLAGS = {\n  REASONING_STREAMING:\n    (process.env.NEXT_PUBLIC_FEATURE_REASONING_STREAMING || '0').toLowerCase() === '1' ||\n    (process.env.NEXT_PUBLIC_FEATURE_REASONING_STREAMING || '').toLowerCase() === 'true',\n  SHOW_VOICE_OVERLAY:\n    (process.env.NEXT_PUBLIC_FEATURE_VOICE_OVERLAY || '1').toLowerCase() === '1' ||\n    (process.env.NEXT_PUBLIC_FEATURE_VOICE_OVERLAY || '').toLowerCase() === 'true',\n  SHOW_USAGE_CARD:\n    (process.env.NEXT_PUBLIC_FEATURE_SHOW_USAGE_CARD || '0').toLowerCase() === '1' ||\n    (process.env.NEXT_PUBLIC_FEATURE_SHOW_USAGE_CARD || '').toLowerCase() === 'true',\n  // Controls whether the primary chat experience is the dedicated /live page\n} as const\n\n// Agent Stage Configuration - User-friendly stage descriptions\nexport const AGENT_STAGE_CONFIG = {\n  DISCOVERY: {\n    label: \"Discovery\",\n    description: \"Understanding your business needs and goals\",\n    order: 1\n  },\n  SCORING: {\n    label: \"Analysis\",\n    description: \"Evaluating solution fit for your situation\",\n    order: 2\n  },\n  WORKSHOP_PITCH: {\n    label: \"Workshop Solution\",\n    description: \"Designing training approach for your team\",\n    order: 3\n  },\n  CONSULTING_PITCH: {\n    label: \"Custom Solution\",\n    description: \"Architecting enterprise AI implementation\",\n    order: 3\n  },\n  CLOSING: {\n    label: \"Proposal\",\n    description: \"Finalizing next steps and addressing questions\",\n    order: 4\n  },\n  SUMMARY: {\n    label: \"Summary\",\n    description: \"Preparing your personalized strategy report\",\n    order: 5\n  }\n} as const\n\n// Agent UI Configuration (canonical)\nexport const AGENT_UI_CONFIG = {\n  websocketUrl: WEBSOCKET_CONFIG.URL,\n  features: {\n    voice: true,\n    video: true,\n    screenShare: true,\n    chat: true,\n    transcripts: true,\n  },\n  reconnectAttempts: WEBSOCKET_CONFIG.MAX_RECONNECT_ATTEMPTS,\n  reconnectDelay: WEBSOCKET_CONFIG.RECONNECT_DELAY,\n  isPreConnectBufferEnabled: true,\n  agentName: 'fbc-agent',\n  model: GEMINI_MODELS.DEFAULT_VOICE,\n} as const\n\n// Admin Configuration\nexport const ADMIN_CONFIG = {\n  ADMIN_ID: 'farzad',\n  ADMIN_EMAIL: 'farzad@bayatconsulting.com',\n} as const\n"
  },
  "config/env": {
    "status": "identical",
    "differences": [],
    "stats": {
      "source": {
        "lines": 50,
        "exports": 2,
        "functions": 3,
        "classes": 0
      },
      "target": {
        "lines": 50,
        "exports": 2,
        "functions": 3,
        "classes": 0
      }
    },
    "content1": "/**\n * Environment resolution helpers\n * Centralizes how we read and normalize environment variables so\n * production (Vercel) and local dev behave the same.\n */\n\nimport { GoogleGenAI } from '@google/genai'\n\n/**\n * Resolve the Google/Gemini API key from any supported env var.\n * \n * IMPORTANT: This function is pure - it does NOT mutate global process.env.\n * The key is returned directly and passed to SDK constructors, preventing\n * Google from detecting the key as \"leaked\" when it appears in both env vars\n * and instance config simultaneously.\n */\nexport function getResolvedGeminiApiKey(): string {\n  const key =\n    process.env.GEMINI_API_KEY ||\n    process.env.GOOGLE_GEMINI_API_KEY ||\n    process.env.GOOGLE_GENERATIVE_AI_API_KEY ||\n    process.env.GOOGLE_API_KEY ||\n    ''\n\n  if (!key) {\n    throw new Error('Missing Google Generative AI API key (set GEMINI_API_KEY or GOOGLE_GENERATIVE_AI_API_KEY)')\n  }\n\n  // Return key directly without mutating global process.env\n  // This prevents Google from detecting keys as \"leaked\" when they appear\n  // in both env vars and instance config\n  return key\n}\n\n/**\n * Create a GoogleGenAI instance using API key directly.\n * \n * NOTE: For Google Grounding/search, we use API key directly (matches v7's working approach).\n * Service account is only used for Live API (voice), not for REST API calls.\n * \n * IMPORTANT: The SDK checks credentials at initialization time, not just request time.\n * Always create instances INSIDE `withApiKeyOnly()` wrapper to ensure service account\n * is unset before the SDK reads credentials.\n */\nexport function createGoogleGenAI(): GoogleGenAI {\n  const apiKey = getResolvedGeminiApiKey()\n  return new GoogleGenAI({ apiKey })\n}\n\n",
    "content2": "/**\n * Environment resolution helpers\n * Centralizes how we read and normalize environment variables so\n * production (Vercel) and local dev behave the same.\n */\n\nimport { GoogleGenAI } from '@google/genai'\n\n/**\n * Resolve the Google/Gemini API key from any supported env var.\n * \n * IMPORTANT: This function is pure - it does NOT mutate global process.env.\n * The key is returned directly and passed to SDK constructors, preventing\n * Google from detecting the key as \"leaked\" when it appears in both env vars\n * and instance config simultaneously.\n */\nexport function getResolvedGeminiApiKey(): string {\n  const key =\n    process.env.GEMINI_API_KEY ||\n    process.env.GOOGLE_GEMINI_API_KEY ||\n    process.env.GOOGLE_GENERATIVE_AI_API_KEY ||\n    process.env.GOOGLE_API_KEY ||\n    ''\n\n  if (!key) {\n    throw new Error('Missing Google Generative AI API key (set GEMINI_API_KEY or GOOGLE_GENERATIVE_AI_API_KEY)')\n  }\n\n  // Return key directly without mutating global process.env\n  // This prevents Google from detecting keys as \"leaked\" when they appear\n  // in both env vars and instance config\n  return key\n}\n\n/**\n * Create a GoogleGenAI instance using API key directly.\n * \n * NOTE: For Google Grounding/search, we use API key directly (matches v7's working approach).\n * Service account is only used for Live API (voice), not for REST API calls.\n * \n * IMPORTANT: The SDK checks credentials at initialization time, not just request time.\n * Always create instances INSIDE `withApiKeyOnly()` wrapper to ensure service account\n * is unset before the SDK reads credentials.\n */\nexport function createGoogleGenAI(): GoogleGenAI {\n  const apiKey = getResolvedGeminiApiKey()\n  return new GoogleGenAI({ apiKey })\n}\n\n"
  }
}